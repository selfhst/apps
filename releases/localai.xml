<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://selfh.st/apps</id>
  <title>LocalAI Releases</title>
  <updated>2025-06-17T18:36:22.710875-04:00</updated>
  <author>
    <name>selfh.st</name>
    <email>contact@selfh.st</email>
  </author>
  <link href="https://selfh.st/apps" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <subtitle>Self-hosted software releases generated by selfh.st</subtitle>
  <entry>
    <id>https://github.com/mudler/LocalAI/releases/tag/v2.25.0</id>
    <title>New release for LocalAI: v2.25.0</title>
    <updated>2025-01-10T17:02:48-05:00</updated>
    <author>
      <name>mudler/LocalAI</name>
    </author>
    <content>&lt;!-- Release notes generated using configuration in .github/release.yml at master --&gt;

&lt;h2&gt;What's Changed&lt;/h2&gt;
&lt;h3&gt;Bug fixes :bug:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;chore(llava): update clip.patch by @mudler in https://github.com/mudler/LocalAI/pull/4453&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Exciting New Features 🎉&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;feat(llama.cpp): expose cache_type_k and cache_type_v for quant of kv cache by @mudler in https://github.com/mudler/LocalAI/pull/4329&lt;/li&gt;
&lt;li&gt;feat(template): read jinja templates from gguf files by @mudler in https://github.com/mudler/LocalAI/pull/4332&lt;/li&gt;
&lt;li&gt;feat: stream tokens usage by @mintyleaf in https://github.com/mudler/LocalAI/pull/4415&lt;/li&gt;
&lt;li&gt;feat(Dockerfile): allow to skip driver installation by @mudler in https://github.com/mudler/LocalAI/pull/4447&lt;/li&gt;
&lt;li&gt;feat(ui): path prefix support via HTTP header by @mgoltzsche in https://github.com/mudler/LocalAI/pull/4497&lt;/li&gt;
&lt;li&gt;feat(dowloader): resume partial downloads by @Saavrm26 in https://github.com/mudler/LocalAI/pull/4537&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;🧠 Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;chore(model gallery): add rp-naughty-v1.0c-8b by @mudler in https://github.com/mudler/LocalAI/pull/4322&lt;/li&gt;
&lt;li&gt;chore(model gallery): add loki-v2.6-8b-1024k by @mudler in https://github.com/mudler/LocalAI/pull/4321&lt;/li&gt;
&lt;li&gt;chore(model gallery): add math-iio-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4323&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-3.3-70b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4333&lt;/li&gt;
&lt;li&gt;chore(model gallery): add mn-chunky-lotus-12b by @mudler in https://github.com/mudler/LocalAI/pull/4337&lt;/li&gt;
&lt;li&gt;chore(model gallery): add virtuoso-small by @mudler in https://github.com/mudler/LocalAI/pull/4338&lt;/li&gt;
&lt;li&gt;chore(model gallery): add bio-medical-llama-3-8b by @mudler in https://github.com/mudler/LocalAI/pull/4339&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwen2.5-7b-homeranvita-nerdmix by @mudler in https://github.com/mudler/LocalAI/pull/4343&lt;/li&gt;
&lt;li&gt;chore(model gallery): add impish_mind_8b by @mudler in https://github.com/mudler/LocalAI/pull/4344&lt;/li&gt;
&lt;li&gt;chore(model gallery): add tulu-3.1-8b-supernova-smart by @mudler in https://github.com/mudler/LocalAI/pull/4347&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwen2.5-math-14b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4355&lt;/li&gt;
&lt;li&gt;chore(model gallery): add intellect-1-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4356&lt;/li&gt;
&lt;li&gt;chore(model gallery): add b-nimita-l3-8b-v0.02 by @mudler in https://github.com/mudler/LocalAI/pull/4357&lt;/li&gt;
&lt;li&gt;chore(model gallery): add sailor2-1b-chat by @mudler in https://github.com/mudler/LocalAI/pull/4363&lt;/li&gt;
&lt;li&gt;chore(model gallery): add sailor2-8b-chat by @mudler in https://github.com/mudler/LocalAI/pull/4364&lt;/li&gt;
&lt;li&gt;chore(model gallery): add sailor2-20b-chat by @mudler in https://github.com/mudler/LocalAI/pull/4365&lt;/li&gt;
&lt;li&gt;chore(model gallery): add 72b-qwen2.5-kunou-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4369&lt;/li&gt;
&lt;li&gt;chore(model gallery): add deepthought-8b-llama-v0.01-alpha by @mudler in https://github.com/mudler/LocalAI/pull/4370&lt;/li&gt;
&lt;li&gt;chore(model gallery): add l3.3-70b-euryale-v2.3 by @mudler in https://github.com/mudler/LocalAI/pull/4371&lt;/li&gt;
&lt;li&gt;chore(model gallery): add l3.3-ms-evayale-70b by @mudler in https://github.com/mudler/LocalAI/pull/4374&lt;/li&gt;
&lt;li&gt;chore(model gallery): add evathene-v1.3 by @mudler in https://github.com/mudler/LocalAI/pull/4375&lt;/li&gt;
&lt;li&gt;chore(model gallery): add hermes-3-llama-3.2-3b by @mudler in https://github.com/mudler/LocalAI/pull/4376&lt;/li&gt;
&lt;li&gt;chore(model gallery): add fusechat-gemma-2-9b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4379&lt;/li&gt;
&lt;li&gt;chore(model gallery): add fusechat-qwen-2.5-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4380&lt;/li&gt;
&lt;li&gt;chore(model gallery): add chronos-gold-12b-1.0 by @mudler in https://github.com/mudler/LocalAI/pull/4381&lt;/li&gt;
&lt;li&gt;fix: correct gallery/index.yaml by @godsey in https://github.com/mudler/LocalAI/pull/4384&lt;/li&gt;
&lt;li&gt;chore(model gallery): add fusechat-llama-3.2-3b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4386&lt;/li&gt;
&lt;li&gt;chore(model gallery): add fusechat-llama-3.1-8b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4387&lt;/li&gt;
&lt;li&gt;chore(model gallery): add neumind-math-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4388&lt;/li&gt;
&lt;li&gt;chore(model gallery): add naturallm-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4392&lt;/li&gt;
&lt;li&gt;chore(model gallery): add marco-o1-uncensored by @mudler in https://github.com/mudler/LocalAI/pull/4393&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwen2-7b-multilingual-rp by @mudler in https://github.com/mudler/LocalAI/pull/4394&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwq-lcot-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4419&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-openreviewer-8b by @mudler in https://github.com/mudler/LocalAI/pull/4422&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-1b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4423&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-3b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4424&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwen2-vl-72b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4425&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-10b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4426&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-song-stream-3b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4431&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-chat-summary-3.2-3b by @mudler in https://github.com/mudler/LocalAI/pull/4432&lt;/li&gt;
&lt;li&gt;chore(model gallery): add tq2.5-14b-aletheia-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4440&lt;/li&gt;
&lt;li&gt;chore(model gallery): add tq2.5-14b-neon-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4441&lt;/li&gt;
&lt;li&gt;chore(model gallery): add orca_mini_v8_1_70b by @mudler in https://github.com/mudler/LocalAI/pull/4444&lt;/li&gt;
&lt;li&gt;chore(model gallery): add anubis-70b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4446&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-3.3-70b-instruct-ablated by @mudler in https://github.com/mudler/LocalAI/pull/4448&lt;/li&gt;
&lt;li&gt;chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/4487&lt;/li&gt;
&lt;li&gt;chore(model gallery): add l3.3-ms-evalebis-70b by @mudler in https://github.com/mudler/LocalAI/pull/4488&lt;/li&gt;
&lt;li&gt;chore(model gallery): add tqwendo-36b by @mudler in https://github.com/mudler/LocalAI/pull/4489&lt;/li&gt;
&lt;li&gt;chore(model gallery): add rombos-llm-70b-llama-3.3 by @mudler in https://github.com/mudler/LocalAI/pull/4490&lt;/li&gt;
&lt;li&gt;chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/4492&lt;/li&gt;
&lt;li&gt;chore(model gallery): add fastllama-3.2-1b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4493&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dans-personalityengine-v1.1.0-12b by @mudler in https://github.com/mudler/LocalAI/pull/4494&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-3.1-8b-open-sft by @mudler in https://github.com/mudler/LocalAI/pull/4495&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qvq-72b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4498&lt;/li&gt;
&lt;li&gt;chore(model gallery): add teleut-7b-rp by @mudler in https://github.com/mudler/LocalAI/pull/4499&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-1b-instruct-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4501&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-3b-instruct-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4502&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-10b-instruct-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4503&lt;/li&gt;
&lt;li&gt;chore(model gallery): add falcon3-7b-instruct-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4504&lt;/li&gt;
&lt;li&gt;chore(model gallery): add control-nanuq-8b by @mudler in https://github.com/mudler/LocalAI/pull/4506&lt;/li&gt;
&lt;li&gt;chore(model gallery): add miscii-14b-1028 by @mudler in https://github.com/mudler/LocalAI/pull/4507&lt;/li&gt;
&lt;li&gt;chore(model gallery): add miscii-14b-1225 by @mudler in https://github.com/mudler/LocalAI/pull/4508&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwen2.5-32b-rp-ink by @mudler in https://github.com/mudler/LocalAI/pull/4517&lt;/li&gt;
&lt;li&gt;chore(model gallery): add huatuogpt-o1-8b by @mudler in https://github.com/mudler/LocalAI/pull/4518&lt;/li&gt;
&lt;li&gt;chore(model gallery): add q2.5-veltha-14b-0.5 by @mudler in https://github.com/mudler/LocalAI/pull/4519&lt;/li&gt;
&lt;li&gt;chore(model gallery): add smallthinker-3b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4521&lt;/li&gt;
&lt;li&gt;chore(model gallery): add mn-12b-mag-mell-r1-iq-arm-imatrix by @mudler in https://github.com/mudler/LocalAI/pull/4522&lt;/li&gt;
&lt;li&gt;chore(model gallery): add captain-eris-diogenes_twilight-v0.420-12b by @mudler in https://github.com/mudler/LocalAI/pull/4523&lt;/li&gt;
&lt;li&gt;chore(model gallery): add violet_twilight-v0.2 by @mudler in https://github.com/mudler/LocalAI/pull/4524&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwenwify2.5-32b-v4.5 by @mudler in https://github.com/mudler/LocalAI/pull/4525&lt;/li&gt;
&lt;li&gt;chore(model gallery): add sainemo-remix by @mudler in https://github.com/mudler/LocalAI/pull/4526&lt;/li&gt;
&lt;li&gt;chore(model gallery): add l3.1-purosani-2-8b by @mudler in https://github.com/mudler/LocalAI/pull/4527&lt;/li&gt;
&lt;li&gt;chore(model gallery): add nera_noctis-12b by @mudler in https://github.com/mudler/LocalAI/pull/4530&lt;/li&gt;
&lt;li&gt;chore(model gallery): add drt-o1-7b by @mudler in https://github.com/mudler/LocalAI/pull/4533&lt;/li&gt;
&lt;li&gt;chore(model gallery): add codepy-deepthink-3b by @mudler in https://github.com/mudler/LocalAI/pull/4534&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama3.1-8b-prm-deepseek-data by @mudler in https://github.com/mudler/LocalAI/pull/4535&lt;/li&gt;
&lt;li&gt;chore(model gallery): add experimental-lwd-mirau-rp-14b-iq-imatrix by @mudler in https://github.com/mudler/LocalAI/pull/4539&lt;/li&gt;
&lt;li&gt;chore(model gallery): add llama-deepsync-3b by @mudler in https://github.com/mudler/LocalAI/pull/4540&lt;/li&gt;
&lt;li&gt;chore(model gallery): add qwentile2.5-32b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4541&lt;/li&gt;
&lt;li&gt;chore(model gallery): add 32b-qwen2.5-kunou-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4545&lt;/li&gt;
&lt;li&gt;chore(model gallery): add triangulum-10b by @mudler in https://github.com/mudler/LocalAI/pull/4546&lt;/li&gt;
&lt;li&gt;chore(model gallery): add 14b-qwen2.5-kunou-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4547&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-llama3.1-8b by @mudler in https://github.com/mudler/LocalAI/pull/4553&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-llama3.2-1b by @mudler in https://github.com/mudler/LocalAI/pull/4554&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-llama3.2-3b by @mudler in https://github.com/mudler/LocalAI/pull/4555&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-qwen2.5-0.5b by @mudler in https://github.com/mudler/LocalAI/pull/4558&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-qwen2.5-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/4559&lt;/li&gt;
&lt;li&gt;chore(model gallery): add dolphin3.0-qwen2.5-3b by @mudler in https://github.com/mudler/LocalAI/pull/4560&lt;/li&gt;
&lt;li&gt;chore(model gallery): add phi-4 by @mudler in https://github.com/mudler/LocalAI/pull/4562&lt;/li&gt;
&lt;li&gt;chore(model gallery): add 14b-qwen2.5-freya-x1 by @mudler in https://github.com/mudler/LocalAI/pull/4566&lt;/li&gt;
&lt;li&gt;chore(model gallery): add minithinky-v2-1b-llama-3.2 by @mudler in https://github.com/mudler/LocalAI/pull/4567&lt;/li&gt;
&lt;li&gt;chore(model gallery): add huatuogpt-o1-7b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/4568&lt;/li&gt;
&lt;li&gt;chore(model gallery): add 70b-l3.3-cirrus-x1 by @mudler in https://github.com/mudler/LocalAI/pull/4569&lt;/li&gt;
&lt;li&gt;chore(model gallery): add gwq-9b-preview2 by @mudler in https://github.com/mudler/LocalAI/pull/4572&lt;/li&gt;
&lt;li&gt;chore(model gallery): add chuluun-qwen2.5-72b-v0.01 by @mudler in https://github.com/mudler/LocalAI/pull/4573&lt;/li&gt;
&lt;li&gt;chore(model gallery): add phi-3.5-moe-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4574&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;📖 Documentation and examples&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;chore(docs): update available backends by @mudler in https://github.com/mudler/LocalAI/pull/4325&lt;/li&gt;
&lt;li&gt;chore(docs): patch p2p detail in env and docs by @jtwolfe in https://github.com/mudler/LocalAI/pull/4434&lt;/li&gt;
&lt;li&gt;docs: update compatibility-table.md by @mudler in https://github.com/mudler/LocalAI/pull/4557&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;👒 Dependencies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;59f4db10883a4f3e855cffbf2c3ab68430e95272&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4319&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update leejet/stable-diffusion.cpp to &lt;code&gt;9578fdcc4632dc3de5565f28e2fb16b7c18f8d48&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4320&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;c9c6e01daedac542b174c235872569fce5385982&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4328&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;c5ede3849fc021174862f9c0bf8273808d8f0d39&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4330&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;3573fa8e7b7f0865638b52b4e9b4d2006f0558a2&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4335&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;e52522b8694ae73abf12feb18d29168674aa1c1b&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4342&lt;/li&gt;
&lt;li&gt;chore(deps): Bump docs/themes/hugo-theme-relearn from &lt;code&gt;be85052&lt;/code&gt; to &lt;code&gt;bd1f3d3&lt;/code&gt; by @dependabot in https://github.com/mudler/LocalAI/pull/4348&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;26a8406ba9198eb6fdd8329fa717555b4f77f05f&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4353&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;dafae66cc242eb766797194d3c85c5e502625623&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4360&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;235f6e14bf0ed0211c51aeff14139038ae1000aa&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4366&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;274ec65af6e54039eb95cb44904af5c945dca1fa&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4372&lt;/li&gt;
&lt;li&gt;feat(llama.cpp): bump and adapt to upstream changes by @mudler in https://github.com/mudler/LocalAI/pull/4378&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;e52aba537a34d51a65cddec6bc6dafc9031edc63&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4385&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;a0974156f334acf8af5858d7ede5ab7d7490d415&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4391&lt;/li&gt;
&lt;li&gt;chore(llama.cpp): bump, drop penalize_nl by @mudler in https://github.com/mudler/LocalAI/pull/4418&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;081b29bd2a3d91e7772e3910ce223dd63b8d7d26&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4421&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;0bf2d10c5514ff61b99897a4a5054f846e384e1e&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4429&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;cd920d0ac38ec243605a5a57c50941140a193f9e&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4433&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;d408bb9268a988c5a60a5746d3a6430386e7604d&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4437&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;eb5c3dc64bd967f2e23c87d9dec195f45468de60&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4442&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;5cd85b5e008de2ec398d6596e240187d627561e3&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4445&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;ebdee9478ca7ba65497b9b96f7457698c6ee5115&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4451&lt;/li&gt;
&lt;li&gt;chore(deps): Bump docs/themes/hugo-theme-relearn from &lt;code&gt;bd1f3d3&lt;/code&gt; to &lt;code&gt;ec88e24&lt;/code&gt; by @dependabot in https://github.com/mudler/LocalAI/pull/4460&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;32d6ee6385b3fc908b283f509b845f757a6e7206&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4486&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;2cd43f4900ba0e34124fdcbf02a7f9df25a10a3d&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4491&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;9ba399dfa7f115effc63d48e6860a94c9faa31b2&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4496&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;d79d8f39b4da6deca4aea8bf130c6034c482b320&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4500&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;f865ea149d71ef883e3780fced8a20a1464eccf4&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4510&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;a813badbbdf0d38705f249df7a0c99af5cdee678&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4512&lt;/li&gt;
&lt;li&gt;chore(deps): Bump gradio from 3.48.0 to 5.9.1 in /backend/python/openvoice by @dependabot in https://github.com/mudler/LocalAI/pull/4514&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update leejet/stable-diffusion.cpp to &lt;code&gt;dcf91f9e0f2cbf9da472ee2a556751ed4bab2d2a&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4509&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;716bd6dec3e044e5c325386b5b0483392b24cefe&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4516&lt;/li&gt;
&lt;li&gt;chore(deps): Bump docs/themes/hugo-theme-relearn from &lt;code&gt;ec88e24&lt;/code&gt; to &lt;code&gt;d25f856&lt;/code&gt; by @dependabot in https://github.com/mudler/LocalAI/pull/4515&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;0827b2c1da299805288abbd556d869318f2b121e&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4520&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;2f0ee84b9b02d2a98742308026f060ebdc2423f1&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4528&lt;/li&gt;
&lt;li&gt;chore(deps): bump llama.cpp to 4b0c638b9 by @mudler in https://github.com/mudler/LocalAI/pull/4532&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;9394bbd484f802ce80d2858033583af3ef700d25&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4536&lt;/li&gt;
&lt;li&gt;chore(deps): bump grpcio to 1.69.0 by @mudler in https://github.com/mudler/LocalAI/pull/4543&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;b56f079e28fda692f11a8b59200ceb815b05d419&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4544&lt;/li&gt;
&lt;li&gt;chore(deps): Bump docs/themes/hugo-theme-relearn from &lt;code&gt;d25f856&lt;/code&gt; to &lt;code&gt;80e448e&lt;/code&gt; by @dependabot in https://github.com/mudler/LocalAI/pull/4549&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;ecebbd292d741ac084cf248146b2cfb17002aa1d&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4552&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;53ff6b9b9fb25ed0ec0a213e05534fe7c3d0040f&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4556&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;8d59d911711b8f1ba9ec57c4b192ccd2628af033&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4561&lt;/li&gt;
&lt;li&gt;chore(deps): bump edgevpn to v0.29.0 by @mudler in https://github.com/mudler/LocalAI/pull/4564&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;1204f9727005974587d6fc1dcd4d4f0ead87c856&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4570&lt;/li&gt;
&lt;li&gt;chore: :arrow_up: Update ggerganov/llama.cpp to &lt;code&gt;ba8a1f9c5b675459c55a83e3f97f10df3a66c788&lt;/code&gt; by @localai-bot in https://github.com/mudler/LocalAI/pull/4575&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Other Changes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Updated links of yamls by @PetrFlegr in https://github.com/mudler/LocalAI/pull/4324&lt;/li&gt;
&lt;li&gt;docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/4327&lt;/li&gt;
&lt;li&gt;Revert "feat: include tokens usage for streamed output" by @mudler in https://github.com/mudler/LocalAI/pull/4336&lt;/li&gt;
&lt;li&gt;docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/4341&lt;/li&gt;
&lt;li&gt;docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/4359&lt;/li&gt;
&lt;li&gt;fix(python): remove pin to setuptools, pin python version by @mudler in https://github.com/mudler/LocalAI/pull/4395&lt;/li&gt;
&lt;li&gt;chore(tests): stabilize tts test by @mudler in https://github.com/mudler/LocalAI/pull/4417&lt;/li&gt;
&lt;li&gt;fix(intel): pin torch and intel-extensions by @mudler in https://github.com/mudler/LocalAI/pull/4435&lt;/li&gt;
&lt;li&gt;fix(deps): pin openvoice pytorch/torchaudio by @mudler in https://github.com/mudler/LocalAI/pull/4436&lt;/li&gt;
&lt;li&gt;fix(openvoice): do not pin numpy by @mudler in https://github.com/mudler/LocalAI/pull/4438&lt;/li&gt;
&lt;li&gt;fix(openvoice): pin numpy before installing torch by @mudler in https://github.com/mudler/LocalAI/pull/4439&lt;/li&gt;
&lt;li&gt;chore(nvidia-l4t): add l4t arm64 images by @mudler in https://github.com/mudler/LocalAI/pull/4449&lt;/li&gt;
&lt;li&gt;chore(ci): comment arm64 job until we find a native CI runner by @mudler in https://github.com/mudler/LocalAI/pull/4452&lt;/li&gt;
&lt;li&gt;chore(docs): add nvidia l4t instructions by @mudler in https://github.com/mudler/LocalAI/pull/4454&lt;/li&gt;
&lt;li&gt;chore: update labeler.yml to include go files by @mudler in https://github.com/mudler/LocalAI/pull/4565&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;New Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@PetrFlegr made their first contribution in https://github.com/mudler/LocalAI/pull/4324&lt;/li&gt;
&lt;li&gt;@godsey made their first contribution in https://github.com/mudler/LocalAI/pull/4384&lt;/li&gt;
&lt;li&gt;@mgoltzsche made their first contribution in https://github.com/mudler/LocalAI/pull/4497&lt;/li&gt;
&lt;li&gt;@Saavrm26 made their first contribution in https://github.com/mudler/LocalAI/pull/4537&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Full Changelog&lt;/strong&gt;: https://github.com/mudler/LocalAI/compare/v2.24.0...v2.25.0&lt;/p&gt;</content>
    <link href="https://github.com/mudler/LocalAI/releases/tag/v2.25.0" rel="alternate"/>
  </entry>
  <entry>
    <id>https://github.com/mudler/LocalAI/releases/tag/v2.26.0</id>
    <title>New release for LocalAI: v2.26.0</title>
    <updated>2025-02-15T12:22:53-05:00</updated>
    <author>
      <name>mudler/LocalAI</name>
    </author>
    <content>&lt;h1 align="center"&gt;
  &lt;br&gt;
&lt;img src="https://github.com/user-attachments/assets/498ac36e-16dd-48f9-b810-131ee4938eb4" style="display: block;margin-left: auto;margin-right: auto;width: 50%;"&gt;
&lt;/h1&gt;

&lt;h1&gt;:llama:  LocalAI v2.26.0!&lt;/h1&gt;
&lt;p&gt;Hey everyone - very excited about this release!&lt;/p&gt;
&lt;p&gt;It contains several cleanups, performance improvements and few breaking changes: old backends that are now superseded have been removed (for example, &lt;code&gt;vall-e-x&lt;/code&gt;), while new backends have been added to expand the range of model architectures that LocalAI can support. While most of the changes are tested, if you encounter issues with the new backends or migrated ones please file a new issue.&lt;/p&gt;
&lt;p&gt;We also now have support for Nvidia L4T devices (for example, Nvidia AGX Orin) with specific container images. &lt;a href="https://localai.io/docs/reference/nvidia-l4t/"&gt;See the documentation&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h3&gt;:warning: Breaking Changes :warning:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Several backends have been dropped and replaced for improved performance and compatibility.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Vall-e-x&lt;/code&gt; and &lt;code&gt;Openvoice&lt;/code&gt; were deprecated and dropped.&lt;/li&gt;
&lt;li&gt;The stablediffusion-NCN backend was replaced with the stablediffusion-ggml implementation.&lt;/li&gt;
&lt;li&gt;Deprecated llama-ggml backend has been dropped in favor of GGUF support.&lt;/li&gt;
&lt;/ul&gt;
&lt;details&gt;
&lt;summary&gt;
Check all details!
&lt;/summary&gt;

### Backends that were dropped:
- **Vall-e-x and Openvoice:** These projects went silent, and there are better alternatives now. They have been completely superseded by the CoquiTTS community fork, Kokoro, and OutelTTS.
- **Stablediffusion-NCN:** This was the first variant shipped with LocalAI based on the ONNX runtime. It has now been superseded by the stablediffusion-ggml backend, which offers similar capabilities and wider support across more architectures.
- **Llama-ggml backend:** This was the pre-GGUF backend, which is now deprecated. Moving forward, LocalAI will support only GGUF models.

### Notable Backend Changes:
- **Mamba** has moved to the `transformers` backend. 
- **Transformers-Musicgen** has moved to the `transformers` backend.
- **Sentencetransformers** has moved to the `transformers` backend.

While LocalAI will try to alias to the `transformers` backend automatically when using these backends, there might be incompatibilies with your configuration files. Please open an issue if you face any problem!

### New Backends:
- **Kokoro (TTS):** A new backend for text-to-speech.
- **OuteTTS:** A TTS backend with voice cloning capabilities.
- **Fast-Whisper:** A backend designed for faster whisper model inference.

&lt;/details&gt;

&lt;h2&gt;New Features  🎉&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Lazy grammars (llama.cpp):&lt;/strong&gt; Added grammar triggers for llama.cpp: this allow models trained with specific tokens to enable grammar generation when such tokens are seen: this allows precise JSON generation but also consistent output when the model does not need to answer with a tool. For example, in the config file of the model triggers can be specified as such:
&lt;code&gt;yaml
  function:
    grammar:
      triggers:
        word: "&amp;lt;tool_call&amp;gt;"
        at_start: true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Function Argument Parsing Using Named Regex:&lt;/strong&gt; A new feature that allows parsing function arguments with named regular expressions, simplifying function calls.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support for New Backends:&lt;/strong&gt; Added Kokoro, OutelTTS, and Fast-Whisper backends.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diffusers Update:&lt;/strong&gt; Added support for Sana pipelines and image generation option overrides.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Tag and Inference Timing:&lt;/strong&gt; Allows tracking machine performance during inference.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tokenization:&lt;/strong&gt; Introduced tokenization support for llama.cpp to improve text processing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AVX512:&lt;/strong&gt; There is now bundled support for CPUs supporting AVX512 instruction set&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nvidia L4T&lt;/strong&gt;: Support for Nvidia devices on arm64, for example Nvidia AGX Orin and alikes.  &lt;a href="https://localai.io/docs/reference/nvidia-l4t/"&gt;See the documentation&lt;/a&gt;. TLDR; You can start container images ready to go with:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;bash
docker run -e DEBUG=true \
                    -p 8080:8080 \
                    -v $PWD/models:/build/models  \
                   -ti --restart=always --name local-ai \
                   --runtime nvidia --gpus all quay.io/go-skynet/local-ai:master-nvidia-l4t-arm64-core&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Bug Fixes 🐛&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Multiple fixes to improve stability, including enabling SYCL support for stablediffusion-ggml and consistent OpenAI stop reason returns.&lt;/li&gt;
&lt;li&gt;Improved context shift handling for llama.cpp and fixed gallery store overrides.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;🧠 Models:&lt;/h2&gt;
&lt;h1 align="center"&gt;
  &lt;br&gt;
&lt;img src="https://cdn-uploads.huggingface.co/production/uploads/647374aa7ff32a81ac6d35d4/bXvNcxQqQ-wNAnISmx3PS.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%;"&gt;
&lt;/h1&gt;

&lt;p align="center"&gt;
  &lt;br&gt;
&lt;img src="https://cdn-uploads.huggingface.co/production/uploads/647374aa7ff32a81ac6d35d4/Dzbdzn27KEc3K6zNNi070.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%;"&gt;
&lt;/p&gt;

&lt;p&gt;I've fine-tuned a family of models based on o1-cot and function call datasets to work closely with all LocalAI features regarding function calling. The models are tailored to be conversational and execute function calls:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;llama3.2-1b version: https://huggingface.co/mudler/LocalAI-functioncall-llama3.2-1b-v0.4&lt;/li&gt;
&lt;li&gt;llama3.2-3b version: https://huggingface.co/mudler/LocalAI-functioncall-llama3.2-3b-v0.5&lt;/li&gt;
&lt;li&gt;phi-4 version: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/li&gt;
&lt;li&gt;qwen2.5 (7b) version: https://huggingface.co/mudler/LocalAI-functioncall-qwen2.5-7b-v0.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Enjoy! All the models are available in the LocalAI gallery:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
local-ai run LocalAI-functioncall-phi-4-v0.3
local-ai run LocalAI-functioncall-llama3.2-1b-v0.4
local-ai run LocalAI-functioncall-llama3.2-3b-v0.5
local-ai run localai-functioncall-qwen2.5-7b-v0.5&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Other models&lt;/h3&gt;
&lt;p&gt;Numerous model updates and additions:
- New models like nightwing3-10b, rombos-qwen2.5-writer, and negative_llama_70b.
- Updated checksum for model galleries.
- Added icons and improved prompt templates for various models.
- Expanded model gallery with new additions like DeepSeek-R1, Mistral-small-24b, and more.&lt;/p&gt;
&lt;!-- Release notes generated using configuration in .github/release.yml at master --&gt;

&lt;h2&gt;Full changelog :point_down:&lt;/h2&gt;
&lt;details&gt;

&lt;summary&gt;
:point_right: Click to expand :point_left: 
&lt;/summary&gt;

### Breaking Changes 🛠
* chore(vall-e-x): Drop backend by @mudler in https://github.com/mudler/LocalAI/pull/4619
* feat(transformers): merge musicgen functionalities to a single backend by @mudler in https://github.com/mudler/LocalAI/pull/4620
* feat(transformers): merge sentencetransformers backend by @mudler in https://github.com/mudler/LocalAI/pull/4624
* chore(stablediffusion-ncn): drop in favor of ggml implementation by @mudler in https://github.com/mudler/LocalAI/pull/4652
* feat(transformers): add support to Mamba by @mudler in https://github.com/mudler/LocalAI/pull/4669
* chore(openvoice): drop backend by @mudler in https://github.com/mudler/LocalAI/pull/4673
* chore: drop embedded models by @mudler in https://github.com/mudler/LocalAI/pull/4715
* chore(llama-ggml): drop deprecated backend by @mudler in https://github.com/mudler/LocalAI/pull/4775
* fix(llama.cpp): disable mirostat as default by @mudler in https://github.com/mudler/LocalAI/pull/2911
### Bug fixes :bug:
* fix(stablediffusion-ggml): correctly enable sycl by @mudler in https://github.com/mudler/LocalAI/pull/4591
* fix(stablediffusion-ggml): enable oneapi before build by @mudler in https://github.com/mudler/LocalAI/pull/4593
* fix(docs): add missing `-core` suffix to sycl images by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4630
* fix(stores): Stores fixes and testing by @richiejp in https://github.com/mudler/LocalAI/pull/4663
* fix(gallery): do not return overrides and additional config by @mudler in https://github.com/mudler/LocalAI/pull/4768
* fix(openai): consistently return stop reason by @mudler in https://github.com/mudler/LocalAI/pull/4771
* fix(llama.cpp): improve context shift handling by @mudler in https://github.com/mudler/LocalAI/pull/4820
### Exciting New Features 🎉
* feat(stablediffusion-ggml): respect build type by @mudler in https://github.com/mudler/LocalAI/pull/4581
* feat(diffusers): add support for Sana pipelines by @mudler in https://github.com/mudler/LocalAI/pull/4603
* feat(tts): Add Kokoro backend by @mudler in https://github.com/mudler/LocalAI/pull/4616
* feat: add machine tag and inference timings by @mintyleaf in https://github.com/mudler/LocalAI/pull/4577
* feat(transformers): add support to OuteTTS by @mudler in https://github.com/mudler/LocalAI/pull/4622
* Extra-Usage and Machine-Tag docs by @mintyleaf in https://github.com/mudler/LocalAI/pull/4627
* chore: fix some function names in comment by @petercover in https://github.com/mudler/LocalAI/pull/4665
* feat(faster-whisper): add backend by @mudler in https://github.com/mudler/LocalAI/pull/4666
* chore: detect and enable avx512 builds by @mudler in https://github.com/mudler/LocalAI/pull/4675
* chore(downloader): support hf.co and hf:// URIs by @mudler in https://github.com/mudler/LocalAI/pull/4677
* feat: function argument parsing using named regex by @mKenfenheuer in https://github.com/mudler/LocalAI/pull/4700
* feat(llama.cpp): Add support to grammar triggers by @mudler in https://github.com/mudler/LocalAI/pull/4733
* feat: tokenization with llama.cpp by @shraddhazpy in https://github.com/mudler/LocalAI/pull/4724
* feat(diffusers): allow to override image gen options by @mudler in https://github.com/mudler/LocalAI/pull/4807
### 🧠 Models
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/4580
* chore(model gallery): add nightwing3-10b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/4582
* chore(model gallery): add qwq-32b-preview-ideawhiz-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4583
* chore(model gallery): add rombos-qwen2.5-writer-32b by @mudler in https://github.com/mudler/LocalAI/pull/4584
* chore(model gallery): add sky-t1-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4585
* chore(model gallery): add negative_llama_70b by @mudler in https://github.com/mudler/LocalAI/pull/4586
* chore(model gallery): add finemath-llama-3b by @mudler in https://github.com/mudler/LocalAI/pull/4587
* chore(model gallery): add LocalAI-functioncall-phi-4-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/4588
* chore(model gallery): add LocalAI-functioncall-phi-4-v0.2 by @mudler in https://github.com/mudler/LocalAI/pull/4589
* chore(model gallery): add LocalAI-functioncall-phi-4-v0.3 by @mudler in https://github.com/mudler/LocalAI/pull/4599
* chore(model gallery): add negative-anubis-70b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4600
* chore(model gallery): add qwen2.5-72b-rp-ink by @mudler in https://github.com/mudler/LocalAI/pull/4601
* chore(model gallery): add steiner-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4602
* chore(model gallery): add qwerus-7b by @mudler in https://github.com/mudler/LocalAI/pull/4609
* chore(model gallery): add l3.3-ms-nevoria-70b by @mudler in https://github.com/mudler/LocalAI/pull/4610
* chore(model gallery): add lb-reranker-0.5b-v1.0 by @mudler in https://github.com/mudler/LocalAI/pull/4611
* chore(model gallery): add uwu-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4613
* chore(model gallery): add drt-o1-14b by @mudler in https://github.com/mudler/LocalAI/pull/4614
* chore(model gallery): add vikhr-qwen-2.5-1.5b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4615
* chore: remove deprecated tinydream backend by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4631
* chore(model gallery): add MiniCPM-V-2.6-8b-q4_K_M by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4633
* chore(model gallery): add InternLM3-8b-Q4_K_M  by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4637
* fix(model gallery): minicpm-v-2.6 is based on qwen2 by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4638
* chore(model gallery): update icons and add missing ones by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4639
* chore(model gallery): add wayfarer-12b by @mudler in https://github.com/mudler/LocalAI/pull/4641
* chore(model gallery): add l3.3-70b-magnum-v4-se by @mudler in https://github.com/mudler/LocalAI/pull/4642
* chore(model gallery): add l3.3-prikol-70b-v0.2 by @mudler in https://github.com/mudler/LocalAI/pull/4643
* chore(model gallery): remove dead icons and update LLAVA and DeepSeek ones by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4645
* chore(model gallery): add sd-3.5-large-ggml by @mudler in https://github.com/mudler/LocalAI/pull/4647
* chore(model gallery): add Deepseek-R1-Distill models by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4646
* chore(model gallery): add deepseek-r1-distill-qwen-7b by @mudler in https://github.com/mudler/LocalAI/pull/4660
* chore(model gallery): add sd-1.5-ggml and sd-3.5-medium-ggml by @mudler in https://github.com/mudler/LocalAI/pull/4664
* chore(model gallery): add MiniCPM-o-2.6-7.6b by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4676
* chore(model gallery): add DeepSeek R1 14b, 32b and 70b by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4679
* chore(model gallery): add flux.1, stablediffusion and whisper icons by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4680
* chore(model gallery): update deepseek-r1 prompt template by @M0Rf30 in https://github.com/mudler/LocalAI/pull/4686
* chore(model gallery): add lamarck-14b-v0.7 by @mudler in https://github.com/mudler/LocalAI/pull/4687
* chore(model gallery): add art-v0-3b by @mudler in https://github.com/mudler/LocalAI/pull/4688
* chore(model gallery): add chuluun-qwen2.5-72b-v0.08 by @mudler in https://github.com/mudler/LocalAI/pull/4689
* chore(model gallery): add l3.3-nevoria-r1-70b by @mudler in https://github.com/mudler/LocalAI/pull/4691
* chore(model gallery): add dumpling-qwen2.5-32b by @mudler in https://github.com/mudler/LocalAI/pull/4692
* chore(model gallery): add deepseek-r1-qwen-2.5-32b-ablated by @mudler in https://github.com/mudler/LocalAI/pull/4693
* chore(model gallery): add confucius-o1-14b by @mudler in https://github.com/mudler/LocalAI/pull/4696
* chore(model gallery): add fuseo1-deepseekr1-qwen2.5-coder-32b-preview-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/4697
* chore(model gallery): add fuseo1-deepseekr1-qwen2.5-instruct-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4698
* chore(model gallery): add fuseo1-deepseekr1-qwq-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4699
* chore(model gallery): add specific message templates for llama3.2 based models by @mKenfenheuer in https://github.com/mudler/LocalAI/pull/4707
* chore(model gallery): add virtuoso-lite by @mudler in https://github.com/mudler/LocalAI/pull/4718
* chore(model gallery): add selene-1-mini-llama-3.1-8b by @mudler in https://github.com/mudler/LocalAI/pull/4719
* chore(model gallery): add openthinker-7b by @mudler in https://github.com/mudler/LocalAI/pull/4720
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/4723
* chore(model gallery): add mistral-small-24b-instruct-2501 by @mudler in https://github.com/mudler/LocalAI/pull/4725
* chore(model gallery): add tinyswallow-1.5b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4726
* chore(model gallery): add taid-llm-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/4727
* chore(model gallery): add fuseo1-deekseekr1-qwq-skyt1-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4731
* chore(model gallery): add steelskull_l3.3-damascus-r1 by @mudler in https://github.com/mudler/LocalAI/pull/4737
* chore(model gallery): add thedrummer_gemmasutra-pro-27b-v1.1 by @mudler in https://github.com/mudler/LocalAI/pull/4738
* chore(model gallery): add uncensoredai_uncensoredlm-deepseek-r1-distill-qwen-14b by @mudler in https://github.com/mudler/LocalAI/pull/4739
* chore(model gallery): add LocalAI-functioncall-llama3.2-1b-v0.4 by @mudler in https://github.com/mudler/LocalAI/pull/4740
* chore(model gallery): add fblgit_miniclaus-qw1.5b-unamgs-grpo by @mudler in https://github.com/mudler/LocalAI/pull/4758
* chore(model gallery): add nohobby_l3.3-prikol-70b-v0.4 by @mudler in https://github.com/mudler/LocalAI/pull/4759
* chore(model gallery): add suayptalha_maestro-10b by @mudler in https://github.com/mudler/LocalAI/pull/4760
* chore(model gallery): add agi-0_art-skynet-3b by @mudler in https://github.com/mudler/LocalAI/pull/4763
* chore(model gallery): add rubenroy_gilgamesh-72b by @mudler in https://github.com/mudler/LocalAI/pull/4764
* chore(model gallery): add krutrim-ai-labs_krutrim-2-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4765
* chore(model gallery): add LocalAI-functioncall-llama3.2-3b-v0.5 by @mudler in https://github.com/mudler/LocalAI/pull/4766
* chore(model gallery): add arliai_llama-3.3-70b-arliai-rpmax-v1.4 by @mudler in https://github.com/mudler/LocalAI/pull/4772
* chore(model gallery): add tiger-lab_qwen2.5-32b-instruct-cft by @mudler in https://github.com/mudler/LocalAI/pull/4773
* chore(model gallery): add black-ink-guild_pernicious_prophecy_70b by @mudler in https://github.com/mudler/LocalAI/pull/4774
* chore(model gallery): add nohobby_l3.3-prikol-70b-v0.5 by @mudler in https://github.com/mudler/LocalAI/pull/4777
* chore(model gallery): add cognitivecomputations_dolphin3.0-r1-mistral-24b by @mudler in https://github.com/mudler/LocalAI/pull/4778
* chore(model gallery): add cognitivecomputations_dolphin3.0-mistral-24b by @mudler in https://github.com/mudler/LocalAI/pull/4779
* chore(model gallery): add sicariussicariistuff_redemption_wind_24b by @mudler in https://github.com/mudler/LocalAI/pull/4781
* chore(model gallery): add huihui-ai_deepseek-r1-distill-llama-70b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4790
* chore(model gallery): add subtleone_qwen2.5-32b-erudite-writer by @mudler in https://github.com/mudler/LocalAI/pull/4792
* chore(model gallery): add ilsp_llama-krikri-8b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4795
* feat: Centralized Request Processing middleware by @dave-gray101 in https://github.com/mudler/LocalAI/pull/3847
* chore(model gallery): add localai-functioncall-qwen2.5-7b-v0.5 by @mudler in https://github.com/mudler/LocalAI/pull/4796
* chore(model gallery): add agentica-org_deepscaler-1.5b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4804
* chore(model gallery): add simplescaling_s1.1-32b by @mudler in https://github.com/mudler/LocalAI/pull/4812
* chore(model gallery): add theskullery_l3.3-exp-unnamed-model-70b-v0.5 by @mudler in https://github.com/mudler/LocalAI/pull/4813
* chore(model gallery): add nvidia_aceinstruct-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/4819
* chore(model gallery): add nvidia_aceinstruct-7b by @mudler in https://github.com/mudler/LocalAI/pull/4821
* chore(model gallery): add nvidia_aceinstruct-72b by @mudler in https://github.com/mudler/LocalAI/pull/4822
* chore(model gallery): add sicariussicariistuff_phi-lthy4 by @mudler in https://github.com/mudler/LocalAI/pull/4826
* chore(model gallery): add open-thoughts_openthinker-32b by @mudler in https://github.com/mudler/LocalAI/pull/4827
* chore(model gallery): add nousresearch_deephermes-3-llama-3-8b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4828
* chore(model gallery): add rombo-org_rombo-llm-v3.0-qwen-32b by @mudler in https://github.com/mudler/LocalAI/pull/4830
* chore(model gallery): add pygmalionai_eleusis-12b by @mudler in https://github.com/mudler/LocalAI/pull/4832
* chore(model gallery): add davidbrowne17_llamathink-8b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4833
### 📖 Documentation and examples
* docs: update advanced-usage.md to reflect changes in #4700 by @mKenfenheuer in https://github.com/mudler/LocalAI/pull/4709
### 👒 Dependencies
* chore: :arrow_up: Update ggerganov/llama.cpp to `c05e8c9934f94fde49bc1bc9dc51eed282605150` by @localai-bot in https://github.com/mudler/LocalAI/pull/4579
* chore(deps): bump llama.cpp to '924518e2e5726e81f3aeb2518fb85963a500e… by @mudler in https://github.com/mudler/LocalAI/pull/4592
* chore(deps): Bump securego/gosec from 2.21.4 to 2.22.0 by @dependabot in https://github.com/mudler/LocalAI/pull/4594
* chore: :arrow_up: Update ggerganov/llama.cpp to `504af20ee4eae72080a56d59d744f6774f7901ce` by @localai-bot in https://github.com/mudler/LocalAI/pull/4597
* chore: :arrow_up: Update ggerganov/llama.cpp to `b4d92a59a20eea400d8dd30844a339b76210daa0` by @localai-bot in https://github.com/mudler/LocalAI/pull/4606
* chore: :arrow_up: Update ggerganov/llama.cpp to `adc5dd92e8aea98f5e7ac84f6e1bc15de35130b5` by @localai-bot in https://github.com/mudler/LocalAI/pull/4612
* chore: :arrow_up: Update ggerganov/llama.cpp to `4dbc8b9cb71876e005724f4e8f73a3544646bcf5` by @localai-bot in https://github.com/mudler/LocalAI/pull/4618
* chore(deps): Bump scipy from 1.14.0 to 1.15.1 in /backend/python/transformers by @dependabot in https://github.com/mudler/LocalAI/pull/4621
* chore(llama.cpp): update dependency by @mudler in https://github.com/mudler/LocalAI/pull/4628
* chore: :arrow_up: Update leejet/stable-diffusion.cpp to `5eb15ef4d022bef4a391de4f5f6556e81fbb5024` by @localai-bot in https://github.com/mudler/LocalAI/pull/4636
* chore: :arrow_up: Update ggerganov/llama.cpp to `a1649cc13f89946322358f92ea268ae1b7b5096c` by @localai-bot in https://github.com/mudler/LocalAI/pull/4635
* chore: :arrow_up: Update ggerganov/llama.cpp to `92bc493917d43b83e592349e138b54c90b1c3ea7` by @localai-bot in https://github.com/mudler/LocalAI/pull/4640
* chore(deps): Bump docs/themes/hugo-theme-relearn from `80e448e` to `8dad5ee` by @dependabot in https://github.com/mudler/LocalAI/pull/4656
* chore: :arrow_up: Update ggerganov/llama.cpp to `aea8ddd5165d525a449e2fc3839db77a71f4a318` by @localai-bot in https://github.com/mudler/LocalAI/pull/4657
* chore: :arrow_up: Update ggerganov/llama.cpp to `6171c9d25820ccf676b243c172868819d882848f` by @localai-bot in https://github.com/mudler/LocalAI/pull/4661
* chore: :arrow_up: Update ggerganov/llama.cpp to `6152129d05870cb38162c422c6ba80434e021e9f` by @localai-bot in https://github.com/mudler/LocalAI/pull/4668
* chore(parler-tts): drop backend by @mudler in https://github.com/mudler/LocalAI/pull/4672
* chore: :arrow_up: Update ggerganov/llama.cpp to `c5d9effb49649db80a52caf5c0626de6f342f526` by @localai-bot in https://github.com/mudler/LocalAI/pull/4685
* chore: :arrow_up: Update ggerganov/llama.cpp to `26771a1491f3a4c3d5b99c4c267b81aca9a7dfa0` by @localai-bot in https://github.com/mudler/LocalAI/pull/4690
* chore: :arrow_up: Update ggerganov/llama.cpp to `178a7eb952d211b8d4232d5e50ae1b64519172a9` by @localai-bot in https://github.com/mudler/LocalAI/pull/4694
* chore(deps): Bump sentence-transformers from 3.3.1 to 3.4.0 in /backend/python/transformers by @dependabot in https://github.com/mudler/LocalAI/pull/4702
* chore(deps): Bump docs/themes/hugo-theme-relearn from `8dad5ee` to `5bcb9fe` by @dependabot in https://github.com/mudler/LocalAI/pull/4704
* chore: :arrow_up: Update ggerganov/llama.cpp to `a4417ddda98fd0558fb4d802253e68a933704b59` by @localai-bot in https://github.com/mudler/LocalAI/pull/4705
* chore(deps): Bump dependabot/fetch-metadata from 2.2.0 to 2.3.0 by @dependabot in https://github.com/mudler/LocalAI/pull/4701
* chore: :arrow_up: Update ggerganov/llama.cpp to `cae9fb4361138b937464524eed907328731b81f6` by @localai-bot in https://github.com/mudler/LocalAI/pull/4711
* chore: :arrow_up: Update ggerganov/llama.cpp to `eb7cf15a808d4d7a71eef89cc6a9b96fe82989dc` by @localai-bot in https://github.com/mudler/LocalAI/pull/4717
* chore: :arrow_up: Update ggerganov/llama.cpp to `8b576b6c55bc4e6be898b47522f0ef402b93ef62` by @localai-bot in https://github.com/mudler/LocalAI/pull/4722
* chore: :arrow_up: Update ggerganov/llama.cpp to `aa6fb1321333fae8853d0cdc26bcb5d438e650a1` by @localai-bot in https://github.com/mudler/LocalAI/pull/4728
* chore: :arrow_up: Update ggerganov/llama.cpp to `53debe6f3c9cca87e9520a83ee8c14d88977afa4` by @localai-bot in https://github.com/mudler/LocalAI/pull/4732
* chore: :arrow_up: Update ggerganov/llama.cpp to `90f9b88afb6447d3929843a2aa98c0f11074762d` by @localai-bot in https://github.com/mudler/LocalAI/pull/4736
* chore(deps): Bump GrantBirki/git-diff-action from 2.7.0 to 2.8.0 by @dependabot in https://github.com/mudler/LocalAI/pull/4746
* chore: :arrow_up: Update ggerganov/llama.cpp to `5598f475be3e31430fbe17ebb85654ec90dc201e` by @localai-bot in https://github.com/mudler/LocalAI/pull/4757
* chore(deps): Bump sentence-transformers from 3.4.0 to 3.4.1 in /backend/python/transformers by @dependabot in https://github.com/mudler/LocalAI/pull/4748
* chore(deps): Bump docs/themes/hugo-theme-relearn from `5bcb9fe` to `66bc366` by @dependabot in https://github.com/mudler/LocalAI/pull/4750
* chore: :arrow_up: Update ggerganov/llama.cpp to `3ec9fd4b77b6aca03a3c2bf678eae3f9517d6904` by @localai-bot in https://github.com/mudler/LocalAI/pull/4762
* chore: :arrow_up: Update leejet/stable-diffusion.cpp to `d46ed5e184b97c2018dc2e8105925bdb8775e02c` by @localai-bot in https://github.com/mudler/LocalAI/pull/4769
* chore: :arrow_up: Update ggerganov/llama.cpp to `d774ab3acc4fee41fbed6dbfc192b57d5f79f34b` by @localai-bot in https://github.com/mudler/LocalAI/pull/4770
* chore: :arrow_up: Update ggerganov/llama.cpp to `8a59053f63fffc24e730cd3ea067760abfe4a919` by @localai-bot in https://github.com/mudler/LocalAI/pull/4776
* chore: :arrow_up: Update ggerganov/llama.cpp to `d2fe216fb2fb7ca8627618c9ea3a2e7886325780` by @localai-bot in https://github.com/mudler/LocalAI/pull/4780
* chore: :arrow_up: Update ggerganov/llama.cpp to `e6e658319952f7ad269dc11275b9edddc721fc6d` by @localai-bot in https://github.com/mudler/LocalAI/pull/4787
* chore: :arrow_up: Update ggerganov/llama.cpp to `19d3c8293b1f61acbe2dab1d49a17950fd788a4a` by @localai-bot in https://github.com/mudler/LocalAI/pull/4793
* chore(deps): Bump docs/themes/lotusdocs from `f5785a2` to `975da91` by @dependabot in https://github.com/mudler/LocalAI/pull/4801
* chore: :arrow_up: Update ggerganov/llama.cpp to `19b392d58dc08c366d0b29bd3b9c6991fa4e1662` by @localai-bot in https://github.com/mudler/LocalAI/pull/4803
* chore: :arrow_up: Update ggerganov/llama.cpp to `90e4dba461b07e635fd1daf3b491c978c7dd0013` by @localai-bot in https://github.com/mudler/LocalAI/pull/4810
* chore: :arrow_up: Update ggerganov/llama.cpp to `0fb77f821f6e70ad8b8247a97d1022f0fef78991` by @localai-bot in https://github.com/mudler/LocalAI/pull/4814
* chore: :arrow_up: Update ggerganov/llama.cpp to `8a8c4ceb6050bd9392609114ca56ae6d26f5b8f5` by @localai-bot in https://github.com/mudler/LocalAI/pull/4825
* chore: :arrow_up: Update ggerganov/llama.cpp to `300907b2110cc17b4337334dc397e05de2d8f5e0` by @localai-bot in https://github.com/mudler/LocalAI/pull/4829
### Other Changes
* docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/4578
* chore(stablediffusion-ggml): disable sycl optimizations by @mudler in https://github.com/mudler/LocalAI/pull/4598
* chore: alias transformers-musicgen to transformers by @mudler in https://github.com/mudler/LocalAI/pull/4623
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/4625
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/4667
* chore(refactor): group cpu cap detection by @mudler in https://github.com/mudler/LocalAI/pull/4674
* chore(deps): bump grpcio to 1.70.0 by @mudler in https://github.com/mudler/LocalAI/pull/4682
* refactor: function argument parsing using named regex by @mKenfenheuer in https://github.com/mudler/LocalAI/pull/4708
* fix(tests): pin to branch for config used in tests by @mudler in https://github.com/mudler/LocalAI/pull/4721
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/4735
* chore: migrate bruno request files to examples repo by @dave-gray101 in https://github.com/mudler/LocalAI/pull/4788
* chore(tests): decrease parallelism for gRPC builds by @mudler in https://github.com/mudler/LocalAI/pull/4797
* chore(grpcio): bump to 1.70 by @mudler in https://github.com/mudler/LocalAI/pull/4798
* chore(grpcio): reduce parallelism by @mudler in https://github.com/mudler/LocalAI/pull/4799
* chore(swagger): update by @mudler in https://github.com/mudler/LocalAI/pull/4805
* Revert "chore(deps): Bump docs/themes/lotusdocs from `f5785a2` to `975da91`" by @mudler in https://github.com/mudler/LocalAI/pull/4808
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/4809

&lt;/details&gt;

&lt;h2&gt;New Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@petercover made their first contribution in https://github.com/mudler/LocalAI/pull/4665&lt;/li&gt;
&lt;li&gt;@mKenfenheuer made their first contribution in https://github.com/mudler/LocalAI/pull/4700&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Full Changelog&lt;/strong&gt;: https://github.com/mudler/LocalAI/compare/v2.25.0...v2.26.0&lt;/p&gt;</content>
    <link href="https://github.com/mudler/LocalAI/releases/tag/v2.26.0" rel="alternate"/>
  </entry>
  <entry>
    <id>https://github.com/mudler/LocalAI/releases/tag/v2.27.0</id>
    <title>New release for LocalAI: v2.27.0</title>
    <updated>2025-03-31T06:32:22-04:00</updated>
    <author>
      <name>mudler/LocalAI</name>
    </author>
    <content>&lt;!-- Release notes generated using configuration in .github/release.yml at master --&gt;
&lt;h1&gt;:rocket:  &lt;strong&gt;LocalAI v2.27.0&lt;/strong&gt;&lt;/h1&gt;
&lt;h1 align="center"&gt;
  &lt;br&gt;
&lt;img src="https://github.com/user-attachments/assets/b3137b56-5661-4aa4-939f-53bde60a5b27" style="display: block;margin-left: auto;margin-right: auto;width: 50%;"&gt;
&lt;/h1&gt;

&lt;p&gt;Welcome to another exciting release of LocalAI v2.27.0! We've been working hard to bring you a fresh WebUI experience and a host of improvements under the hood. Get ready to explore new updates!&lt;/p&gt;
&lt;h2&gt;:fire: AIO Images Updates&lt;/h2&gt;
&lt;p&gt;Check out the updated models we're now shipping with our All-in-One images:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CPU All-in-One&lt;/strong&gt;:
- &lt;strong&gt;Text-to-Text&lt;/strong&gt;: &lt;code&gt;llama3.1&lt;/code&gt;
- &lt;strong&gt;Embeddings&lt;/strong&gt;: &lt;code&gt;granite-embeddings&lt;/code&gt;
- &lt;strong&gt;Vision&lt;/strong&gt;: &lt;code&gt;minicpm&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GPU All-in-One&lt;/strong&gt;:
- &lt;strong&gt;Text-to-Text&lt;/strong&gt;: &lt;code&gt;localai-functioncall-qwen2.5-7b-v0.5&lt;/code&gt; (our tiniest flagship model!)
- &lt;strong&gt;Embeddings&lt;/strong&gt;: &lt;code&gt;granite-embeddings&lt;/code&gt;
- &lt;strong&gt;Vision&lt;/strong&gt;: &lt;code&gt;minicpm&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;💻 WebUI Overhaul!&lt;/h2&gt;
&lt;p&gt;We've given the WebUI a brand-new look and feel. Have a look at the stunning new interface:&lt;/p&gt;
&lt;p&gt;| Talk Interface | Generate Audio |
| --- | --- |
| &lt;img alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" src="https://github.com/user-attachments/assets/9841b1ee-88af-4b96-8ec0-41b17364efa7" /&gt; | &lt;img alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" src="https://github.com/user-attachments/assets/d729f6f4-0621-4715-bda3-35fe6e159524" /&gt; |&lt;/p&gt;
&lt;p&gt;| Models Overview | Generate Images |
| --- | --- |
| &lt;img alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" src="https://github.com/user-attachments/assets/3cf0b918-ba8e-498a-a3cd-485db5984325" /&gt; | &lt;img alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" src="https://github.com/user-attachments/assets/6753d23d-218b-4e07-94b8-9e6c5a4f2311" /&gt; |&lt;/p&gt;
&lt;p&gt;| Chat Interface | API Overview |
| --- | --- |
| &lt;img alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" src="https://github.com/user-attachments/assets/048eab31-0f0c-4d52-a920-3715233f9bf3" /&gt; | &lt;img alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" src="https://github.com/user-attachments/assets/2540e8ce-1a2c-4c12-800c-763bd9be247f" /&gt; |&lt;/p&gt;
&lt;p&gt;| Login | Swarm |
| --- | --- |
|&lt;img alt="Screenshot 2025-03-31 at 12-09-59 " src="https://github.com/user-attachments/assets/5af681b0-dd8e-4fe8-a234-a22f8a040547" /&gt; | &lt;img alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" src="https://github.com/user-attachments/assets/b9527176-63d6-4d2e-8ed1-7fde13a9b0ad" /&gt; |&lt;/p&gt;
&lt;h2&gt;How to Use&lt;/h2&gt;
&lt;p&gt;To get started with LocalAI, you can use our container images. Here’s how to run them with Docker:&lt;/p&gt;
&lt;p&gt;```sh&lt;/p&gt;
&lt;h1&gt;CPU only image:&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-cpu&lt;/p&gt;
&lt;h1&gt;Nvidia GPU:&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12&lt;/p&gt;
&lt;h1&gt;CPU and GPU image (bigger size):&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest&lt;/p&gt;
&lt;h1&gt;AIO images (pre-downloads a set of models ready for use, see https://localai.io/basics/container/)&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu
```&lt;/p&gt;
&lt;p&gt;Check out our &lt;a href="https://localai.io/basics/container/"&gt;Documentation&lt;/a&gt; for more information.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Key Highlights:&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Complete WebUI Redesign&lt;/strong&gt;: A fresh, modern interface with enhanced navigation and visuals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Model Gallery Improvements&lt;/strong&gt;: Easier exploration with improved pagination and filtering.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AIO Image Updates&lt;/strong&gt;: Smoother deployments with updated models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stability Fixes&lt;/strong&gt;: Critical bug fixes in model initialization, embeddings handling, and GPU offloading.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;What’s New :tada:&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Chat Interface Enhancements&lt;/strong&gt;: Cleaner layout, model-specific UI tweaks, and custom reply prefixes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Smart Model Detection&lt;/strong&gt;: Automatically links to relevant model documentation based on use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance Tweaks&lt;/strong&gt;: GGUF models now auto-detect context size, and Llama.cpp handles batch embeddings and SIGTERM gracefully.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VLLM Config Boost&lt;/strong&gt;: Added options to disable logging, set dtype, and enforce per-prompt media limits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New model architecture supported&lt;/strong&gt;: Gemma 3, Mistral, Deepseek&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Bug Fixes :bug:&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Resolved model icon display inconsistencies.&lt;/li&gt;
&lt;li&gt;Ensured proper handling of generated artifacts without API key restrictions.&lt;/li&gt;
&lt;li&gt;Optimized CLIP offloading and Llama.cpp process termination.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Stay Tuned!&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;We have some incredibly exciting features and updates lined up for you. While we can't reveal everything just yet. Keep an eye out for our upcoming announcements – you won't want to miss them!&lt;/p&gt;
&lt;h1 align="center"&gt;
  &lt;br&gt;
&lt;img src="https://github.com/user-attachments/assets/4498ed5f-9c49-4bdc-a258-a6dd3cf3faa3" style="display: block;margin-left: auto;margin-right: auto;width: 20%;" width=200&gt;
&lt;/h1&gt;

&lt;p&gt;Do you like the new webui? let us know in the Github discussions!&lt;/p&gt;
&lt;p&gt;Enjoy 🚀&lt;/p&gt;
&lt;h2&gt;Full changelog :point_down:&lt;/h2&gt;
&lt;details&gt;

&lt;summary&gt;
:point_right: Click to expand :point_left: 
&lt;/summary&gt;

## What's Changed
### Bug fixes :bug:
* fix: change initialization order of llama-cpp-avx512 to go before avx2 variant by @bhulsken in https://github.com/mudler/LocalAI/pull/4837
* fix(coqui): pin transformers by @mudler in https://github.com/mudler/LocalAI/pull/4875
* fix(ui): not all models have an Icon by @mudler in https://github.com/mudler/LocalAI/pull/4913
* fix(models): unify usecases identifications by @mudler in https://github.com/mudler/LocalAI/pull/4914
* fix(llama.cpp): correctly handle embeddings in batches by @mudler in https://github.com/mudler/LocalAI/pull/4957
* fix(routes): do not gate generated artifacts via key by @mudler in https://github.com/mudler/LocalAI/pull/4971
* fix(clip): do not imply GPU offload by default by @mudler in https://github.com/mudler/LocalAI/pull/5010
* fix(llama.cpp): properly handle sigterm by @mudler in https://github.com/mudler/LocalAI/pull/5099
### Exciting New Features 🎉
* feat(ui): detect model usage and display link by @mudler in https://github.com/mudler/LocalAI/pull/4864
* feat(vllm): Additional vLLM config options (Disable logging, dtype, and Per-Prompt media limits) by @TheDropZone in https://github.com/mudler/LocalAI/pull/4855
* feat(ui): show only text models in the chat interface by @mudler in https://github.com/mudler/LocalAI/pull/4869
* feat(ui): do also filter tts and image models by @mudler in https://github.com/mudler/LocalAI/pull/4871
* feat(ui): paginate model gallery by @mudler in https://github.com/mudler/LocalAI/pull/4886
* feat(ui): small improvements to chat interface by @mudler in https://github.com/mudler/LocalAI/pull/4907
* feat(ui): improve chat interface by @mudler in https://github.com/mudler/LocalAI/pull/4910
* feat(ui): improvements to index and models page by @mudler in https://github.com/mudler/LocalAI/pull/4918
* feat: allow to specify a reply prefix by @mudler in https://github.com/mudler/LocalAI/pull/4931
* feat(ui): complete design overhaul by @mudler in https://github.com/mudler/LocalAI/pull/4942
* feat(ui): remove api key handling and small ui adjustments by @mudler in https://github.com/mudler/LocalAI/pull/4948
* feat(aio): update AIO image defaults by @mudler in https://github.com/mudler/LocalAI/pull/5002
* feat(gguf): guess default context size from file by @mudler in https://github.com/mudler/LocalAI/pull/5089
### 🧠 Models
* chore(model gallery): add ozone-ai_0x-lite by @mudler in https://github.com/mudler/LocalAI/pull/4835
* chore: update Image generation docs and examples by @mudler in https://github.com/mudler/LocalAI/pull/4841
* chore(model gallery): add kubeguru-llama3.2-3b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/4858
* chore(model gallery): add allenai_llama-3.1-tulu-3.1-8b by @mudler in https://github.com/mudler/LocalAI/pull/4859
* chore(model gallery): add nbeerbower_dumpling-qwen2.5-14b by @mudler in https://github.com/mudler/LocalAI/pull/4860
* chore(model gallery): add nbeerbower_dumpling-qwen2.5-32b-v2 by @mudler in https://github.com/mudler/LocalAI/pull/4861
* chore(model gallery): add nbeerbower_dumpling-qwen2.5-72b by @mudler in https://github.com/mudler/LocalAI/pull/4862
* chore(model gallery): add pygmalionai_pygmalion-3-12b by @mudler in https://github.com/mudler/LocalAI/pull/4866
* chore(model gallery): add open-r1_openr1-qwen-7b by @mudler in https://github.com/mudler/LocalAI/pull/4867
* chore(model gallery): add sentientagi_dobby-unhinged-llama-3.3-70b by @mudler in https://github.com/mudler/LocalAI/pull/4868
* chore(model gallery): add internlm_oreal-32b by @mudler in https://github.com/mudler/LocalAI/pull/4872
* chore(model gallery): add internlm_oreal-deepseek-r1-distill-qwen-7b by @mudler in https://github.com/mudler/LocalAI/pull/4873
* chore(model gallery): add internlm_oreal-7b by @mudler in https://github.com/mudler/LocalAI/pull/4874
* chore(model gallery): add smirki_uigen-t1.1-qwen-14b by @mudler in https://github.com/mudler/LocalAI/pull/4877
* chore(model gallery): add smirki_uigen-t1.1-qwen-7b by @mudler in https://github.com/mudler/LocalAI/pull/4878
* chore(model gallery): add l3.1-8b-rp-ink by @mudler in https://github.com/mudler/LocalAI/pull/4879
* chore(model gallery): add pocketdoc_dans-personalityengine-v1.2.0-24b by @mudler in https://github.com/mudler/LocalAI/pull/4880
* chore(model gallery): add rombo-org_rombo-llm-v3.0-qwen-72b by @mudler in https://github.com/mudler/LocalAI/pull/4882
* chore(model gallery): add ozone-ai_reverb-7b by @mudler in https://github.com/mudler/LocalAI/pull/4883
* chore(model gallery): add arcee-ai_arcee-maestro-7b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4884
* chore(model gallery): add steelskull_l3.3-mokume-gane-r1-70b by @mudler in https://github.com/mudler/LocalAI/pull/4885
* chore(model gallery): add steelskull_l3.3-cu-mai-r1-70b by @mudler in https://github.com/mudler/LocalAI/pull/4892
* chore(model gallery): add steelskull_l3.3-san-mai-r1-70b by @mudler in https://github.com/mudler/LocalAI/pull/4893
* chore(model gallery): add nohobby_l3.3-prikol-70b-extra by @mudler in https://github.com/mudler/LocalAI/pull/4894
* chore(model gallery): add flux.1dev-abliteratedv2 by @mudler in https://github.com/mudler/LocalAI/pull/4895
* chore(model gallery): add sicariussicariistuff_phi-line_14b by @mudler in https://github.com/mudler/LocalAI/pull/4901
* chore(model gallery): add perplexity-ai_r1-1776-distill-llama-70b by @mudler in https://github.com/mudler/LocalAI/pull/4902
* chore(model gallery): add latitudegames_wayfarer-large-70b-llama-3.3 by @mudler in https://github.com/mudler/LocalAI/pull/4903
* chore(model gallery): add locutusque_thespis-llama-3.1-8b by @mudler in https://github.com/mudler/LocalAI/pull/4912
* chore(model gallery): add microsoft_phi-4-mini-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4921
* chore(model gallery): add ozone-research_chirp-01 by @mudler in https://github.com/mudler/LocalAI/pull/4922
* chore(model gallery): add ozone-research_0x-lite by @mudler in https://github.com/mudler/LocalAI/pull/4923
* chore(model gallery): add allenai_olmocr-7b-0225-preview by @mudler in https://github.com/mudler/LocalAI/pull/4924
* chore(model gallery): add ibm-granite_granite-3.2-8b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4927
* chore(model gallery): add ibm-granite_granite-3.2-2b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/4928
* chore(model gallery): add qihoo360_tinyr1-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4929
* chore(model gallery): add thedrummer_fallen-llama-3.3-r1-70b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4930
* chore(model gallery): add steelskull_l3.3-mokume-gane-r1-70b-v1.1 by @mudler in https://github.com/mudler/LocalAI/pull/4933
* chore(model gallery): update qihoo360_tinyr1-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/4937
* chore(model gallery): add l3.3-geneticlemonade-unleashed-70b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4938
* chore(model gallery): add boomer_qwen_72b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4939
* chore(model gallery): add llama-3.3-magicalgirl-2 by @mudler in https://github.com/mudler/LocalAI/pull/4940
* chore(model gallery): add azura-qwen2.5-32b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4941
* chore(model gallery): add llama-3.1-8b-instruct-uncensored-delmat-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4944
* chore(model gallery): add lolzinventor_meta-llama-3.1-8b-survivev3 by @mudler in https://github.com/mudler/LocalAI/pull/4945
* chore(model gallery): add llama-3.3-magicalgirl-2.5-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4946
* chore(model gallery): add qwen_qwq-32b by @mudler in https://github.com/mudler/LocalAI/pull/4952
* chore(model gallery): add rombo-org_rombo-llm-v3.1-qwq-32b by @mudler in https://github.com/mudler/LocalAI/pull/4953
* chore(model gallery): add nomic-embed-text-v1.5 by @mudler in https://github.com/mudler/LocalAI/pull/4955
* chore(model gallery): add granite embeddings models by @mudler in https://github.com/mudler/LocalAI/pull/4956
* chore(model gallery): add steelskull_l3.3-electra-r1-70b by @mudler in https://github.com/mudler/LocalAI/pull/4960
* chore(model gallery): add huihui-ai_qwq-32b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/4961
* chore(model gallery): add goppa-ai_goppa-logillama by @mudler in https://github.com/mudler/LocalAI/pull/4962
* chore(model gallery): add tower-babel_babel-9b-chat by @mudler in https://github.com/mudler/LocalAI/pull/4964
* chore(model gallery): add llmevollama-3.1-8b-v0.1-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4968
* chore(model gallery): add opencrystal-l3-15b-v2.1-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4969
* chore(model gallery): add hyperllama3.1-v2-i1 by @mudler in https://github.com/mudler/LocalAI/pull/4970
* chore(model gallery): add openpipe_deductive-reasoning-qwen-14b by @mudler in https://github.com/mudler/LocalAI/pull/4994
* chore(model gallery): add openpipe_deductive-reasoning-qwen-32b by @mudler in https://github.com/mudler/LocalAI/pull/4995
* chore(model gallery): add thedrummer_gemmasutra-small-4b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/4997
* chore(model gallery): add open-r1_olympiccoder-32b by @mudler in https://github.com/mudler/LocalAI/pull/4998
* chore(model gallery): add open-r1_olympiccoder-7b by @mudler in https://github.com/mudler/LocalAI/pull/4999
* chore(model gallery): add trashpanda-org_qwq-32b-snowdrop-v0 by @mudler in https://github.com/mudler/LocalAI/pull/5000
* chore(model gallery): add gemma-3-27b-it by @mudler in https://github.com/mudler/LocalAI/pull/5003
* chore(model gallery): add gemma-3-12b-it by @mudler in https://github.com/mudler/LocalAI/pull/5007
* chore(model gallery): add gemma-3-4b-it by @mudler in https://github.com/mudler/LocalAI/pull/5008
* chore(model gallery): add gemma-3-1b-it by @mudler in https://github.com/mudler/LocalAI/pull/5009
* chore(model gallery): add models/qgallouedec_gemma-3-27b-it-codeforces-sft by @mudler in https://github.com/mudler/LocalAI/pull/5013
* chore(model gallery): add nousresearch_deephermes-3-mistral-24b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5014
* chore(model gallery): add nousresearch_deephermes-3-llama-3-3b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5015
* chore(model gallery): add prithivmlmods_viper-coder-32b-elite13 by @mudler in https://github.com/mudler/LocalAI/pull/5016
* chore(model gallery): add eurollm-9b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5017
* chore(model gallery): add allura-org_bigger-body-70b by @mudler in https://github.com/mudler/LocalAI/pull/5021
* chore(model gallery): add pocketdoc_dans-sakurakaze-v1.0.0-12b by @mudler in https://github.com/mudler/LocalAI/pull/5023
* chore(model gallery): add beaverai_mn-2407-dsk-qwqify-v0.1-12b by @mudler in https://github.com/mudler/LocalAI/pull/5024
* chore(model gallery): add readyart_forgotten-safeword-70b-3.6 by @mudler in https://github.com/mudler/LocalAI/pull/5027
* chore(model gallery): add mproj files for gemma3 models by @mudler in https://github.com/mudler/LocalAI/pull/5028
* chore(model gallery): add mlabonne_gemma-3-27b-it-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5031
* chore(model gallery): add mlabonne_gemma-3-12b-it-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5032
* chore(model gallery): add mlabonne_gemma-3-4b-it-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5033
* chore(model gallery): add soob3123_amoral-gemma3-12b by @mudler in https://github.com/mudler/LocalAI/pull/5034
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/5036
* chore(model gallery): add mistralai_mistral-small-3.1-24b-instruct-2503 by @mudler in https://github.com/mudler/LocalAI/pull/5039
* chore(model gallery): add gryphe_pantheon-rp-1.8-24b-small-3.1 by @mudler in https://github.com/mudler/LocalAI/pull/5040
* chore(model gallery): add nvidia_llama-3_3-nemotron-super-49b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5041
* chore(model gallery): add gemma-3-4b-it-uncensored-dbl-x-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5043
* chore(model gallery): add rootxhacker_apollo-v3-32b by @mudler in https://github.com/mudler/LocalAI/pull/5044
* chore(model gallery): add samsungsailmontreal_bytecraft by @mudler in https://github.com/mudler/LocalAI/pull/5045
* chore(model gallery): add soob3123_amoral-gemma3-4b by @mudler in https://github.com/mudler/LocalAI/pull/5046
* chore(model gallery): add qwen-writerdemo-7b-s500-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5049
* chore(model gallery): add sao10k_llama-3.3-70b-vulpecula-r1 by @mudler in https://github.com/mudler/LocalAI/pull/5050
* chore(model gallery): add luvgpt_phi3-uncensored-chat by @mudler in https://github.com/mudler/LocalAI/pull/5051
* chore(model gallery): add knoveleng_open-rs3 by @mudler in https://github.com/mudler/LocalAI/pull/5054
* chore(model gallery): add thedrummer_fallen-gemma3-4b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5055
* chore(model gallery): add thedrummer_fallen-gemma3-12b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5056
* chore(model gallery): add thedrummer_fallen-gemma3-27b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5057
* chore(model gallery): add huihui-ai_gemma-3-1b-it-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5058
* chore(model gallery): add mawdistical_mawdistic-nightlife-24b by @mudler in https://github.com/mudler/LocalAI/pull/5059
* chore(model gallery): add sicariussicariistuff_x-ray_alpha by @mudler in https://github.com/mudler/LocalAI/pull/5060
* chore(model gallery): add fiendish_llama_3b by @mudler in https://github.com/mudler/LocalAI/pull/5061
* chore(model gallery): add impish_llama_3b by @mudler in https://github.com/mudler/LocalAI/pull/5064
* chore(model gallery): add eximius_persona_5b by @mudler in https://github.com/mudler/LocalAI/pull/5065
* chore(model gallery): add dusk_rainbow by @mudler in https://github.com/mudler/LocalAI/pull/5066
* chore(model gallery): add jdineen_llama-3.1-8b-think by @mudler in https://github.com/mudler/LocalAI/pull/5069
* chore(model gallery): add helpingai_helpingai3-raw by @mudler in https://github.com/mudler/LocalAI/pull/5070
* chore(model gallery): add alamios_mistral-small-3.1-draft-0.5b by @mudler in https://github.com/mudler/LocalAI/pull/5071
* chore(model gallery): add gemma-3-glitter-12b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5074
* chore(model gallery): add blacksheep-24b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5075
* chore(model gallery): add textsynth-8b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5076
* chore(model gallery): add soob3123_amoral-gemma3-12b-v2 by @mudler in https://github.com/mudler/LocalAI/pull/5080
* chore(model gallery): gemma-3-starshine-12b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5081
* chore(model gallery): qwen2.5-14b-instruct-1m-unalign-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5082
* chore(model gallery): thoughtless-fallen-abomination-70b-r1-v4.1-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5083
* chore(model gallery): fallen-safeword-70b-r1-v4.1 by @mudler in https://github.com/mudler/LocalAI/pull/5084
* chore(model gallery): add tarek07_legion-v2.1-llama-70b by @mudler in https://github.com/mudler/LocalAI/pull/5087
* chore(model gallery): add tesslate_tessa-t1-32b by @mudler in https://github.com/mudler/LocalAI/pull/5088
* chore(model gallery): add tesslate_tessa-t1-14b by @mudler in https://github.com/mudler/LocalAI/pull/5090
* chore(model gallery): add tesslate_tessa-t1-7b by @mudler in https://github.com/mudler/LocalAI/pull/5091
* chore(model gallery): add tesslate_tessa-t1-3b by @mudler in https://github.com/mudler/LocalAI/pull/5092
* chore(model gallery): add chaoticneutrals_very_berry_qwen2_7b by @mudler in https://github.com/mudler/LocalAI/pull/5093
* chore(model gallery): add galactic-qwen-14b-exp1 by @mudler in https://github.com/mudler/LocalAI/pull/5096
* chore(model gallery): add forgotten-abomination-70b-v5.0 by @mudler in https://github.com/mudler/LocalAI/pull/5097
* chore(model gallery): add hammer2.0-7b by @mudler in https://github.com/mudler/LocalAI/pull/5098
### 👒 Dependencies
* chore: :arrow_up: Update ggml-org/llama.cpp to `2eea03d86a2d132c8245468c26290ce07a27a8e8` by @localai-bot in https://github.com/mudler/LocalAI/pull/4839
* chore(deps): Bump edgevpn to v0.30.1 by @mudler in https://github.com/mudler/LocalAI/pull/4840
* chore: :arrow_up: Update ggml-org/llama.cpp to `73e2ed3ce3492d3ed70193dd09ae8aa44779651d` by @localai-bot in https://github.com/mudler/LocalAI/pull/4854
* chore: :arrow_up: Update ggml-org/llama.cpp to `63e489c025d61c7ca5ec06c5d10f36e2b76aaa1d` by @localai-bot in https://github.com/mudler/LocalAI/pull/4865
* chore: :arrow_up: Update ggml-org/llama.cpp to `d04e7163c85a847bc61d58c22f2c503596db7aa8` by @localai-bot in https://github.com/mudler/LocalAI/pull/4870
* chore: :arrow_up: Update ggml-org/llama.cpp to `c392e5094deaf2d1a7c18683214f007fad3fe42b` by @localai-bot in https://github.com/mudler/LocalAI/pull/4876
* chore: :arrow_up: Update ggml-org/llama.cpp to `51f311e057723b7454d0ebe20f545a1a2c4db6b2` by @localai-bot in https://github.com/mudler/LocalAI/pull/4881
* chore: :arrow_up: Update ggml-org/llama.cpp to `a28e0d5eb18c18e6a4598286158f427269b1444e` by @localai-bot in https://github.com/mudler/LocalAI/pull/4887
* chore(stable-diffusion-ggml): update, adapt upstream changes by @mudler in https://github.com/mudler/LocalAI/pull/4889
* chore: :arrow_up: Update ggml-org/llama.cpp to `7ad0779f5de84a68143b2c00ab5dc94a948925d3` by @localai-bot in https://github.com/mudler/LocalAI/pull/4890
* chore(deps): Bump appleboy/ssh-action from 1.2.0 to 1.2.1 by @dependabot in https://github.com/mudler/LocalAI/pull/4896
* chore(deps): Bump docs/themes/hugo-theme-relearn from `66bc366` to `02bba0f` by @dependabot in https://github.com/mudler/LocalAI/pull/4898
* chore: :arrow_up: Update ggml-org/llama.cpp to `7a2c913e66353362d7f28d612fd3c9d51a831eda` by @localai-bot in https://github.com/mudler/LocalAI/pull/4899
* chore: :arrow_up: Update ggml-org/llama.cpp to `d7cfe1ffe0f435d0048a6058d529daf76e072d9c` by @localai-bot in https://github.com/mudler/LocalAI/pull/4908
* chore: :arrow_up: Update ggml-org/llama.cpp to `a800ae46da2ed7dac236aa6bf2b595da6b6294b5` by @localai-bot in https://github.com/mudler/LocalAI/pull/4911
* chore: :arrow_up: Update ggml-org/llama.cpp to `b95c8af37ccf169b0a3216b7ed691af0534e5091` by @localai-bot in https://github.com/mudler/LocalAI/pull/4916
* chore: :arrow_up: Update ggml-org/llama.cpp to `06c2b1561d8b882bc018554591f8c35eb04ad30e` by @localai-bot in https://github.com/mudler/LocalAI/pull/4920
* chore: :arrow_up: Update ggml-org/llama.cpp to `1782cdfed60952f9ff333fc2ab5245f2be702453` by @localai-bot in https://github.com/mudler/LocalAI/pull/4926
* chore: :arrow_up: Update ggml-org/llama.cpp to `14dec0c2f29ae56917907dbf2eed6b19438d0a0e` by @localai-bot in https://github.com/mudler/LocalAI/pull/4932
* chore(deps): Bump docs/themes/hugo-theme-relearn from `02bba0f` to `4a4b60e` by @dependabot in https://github.com/mudler/LocalAI/pull/4934
* chore: :arrow_up: Update ggml-org/llama.cpp to `dfd6b2c0be191b3abe2fd9c1b25deff01c6249d8` by @localai-bot in https://github.com/mudler/LocalAI/pull/4936
* chore: :arrow_up: Update ggml-org/llama.cpp to `5bbe6a9fe9a8796a9389c85accec89dbc4d91e39` by @localai-bot in https://github.com/mudler/LocalAI/pull/4943
* chore(deps): update llama.cpp and sync with upstream changes by @mudler in https://github.com/mudler/LocalAI/pull/4950
* chore: :arrow_up: Update ggml-org/llama.cpp to `3d652bfddfba09022525067e672c3c145c074649` by @localai-bot in https://github.com/mudler/LocalAI/pull/4954
* chore: :arrow_up: Update ggml-org/llama.cpp to `7ab364390f92b0b8d83f69821a536b424838f3f8` by @localai-bot in https://github.com/mudler/LocalAI/pull/4959
* chore: :arrow_up: Update ggml-org/llama.cpp to `0fd7ca7a210bd4abc995cd728491043491dbdef7` by @localai-bot in https://github.com/mudler/LocalAI/pull/4963
* chore: :arrow_up: Update ggml-org/llama.cpp to `1e2f78a00450593e2dfa458796fcdd9987300dfc` by @localai-bot in https://github.com/mudler/LocalAI/pull/4966
* chore(deps): Bump intel-extension-for-pytorch from 2.3.110+xpu to 2.6.10+xpu in /backend/python/diffusers by @dependabot in https://github.com/mudler/LocalAI/pull/4973
* chore(deps): Bump appleboy/ssh-action from 1.2.1 to 1.2.2 by @dependabot in https://github.com/mudler/LocalAI/pull/4978
* chore(deps): Bump docs/themes/hugo-theme-relearn from `4a4b60e` to `9a020e7` by @dependabot in https://github.com/mudler/LocalAI/pull/4988
* chore: :arrow_up: Update ggml-org/llama.cpp to `2c9f833d17bb5b8ea89dec663b072b5420fc5438` by @localai-bot in https://github.com/mudler/LocalAI/pull/4991
* chore: :arrow_up: Update ggml-org/llama.cpp to `10f2e81809bbb69ecfe64fc8b4686285f84b0c07` by @localai-bot in https://github.com/mudler/LocalAI/pull/4996
* chore: :arrow_up: Update ggml-org/llama.cpp to `80a02aa8588ef167d616f76f1781b104c245ace0` by @localai-bot in https://github.com/mudler/LocalAI/pull/5004
* chore: :arrow_up: Update ggml-org/llama.cpp to `f08f4b3187b691bb08a8884ed39ebaa94e956707` by @localai-bot in https://github.com/mudler/LocalAI/pull/5006
* chore: :arrow_up: Update ggml-org/llama.cpp to `84d547554123a62e9ac77107cb20e4f6cc503af4` by @localai-bot in https://github.com/mudler/LocalAI/pull/5011
* chore: :arrow_up: Update ggml-org/llama.cpp to `9f2250ba722738ec0e6ab684636268a79160c854` by @localai-bot in https://github.com/mudler/LocalAI/pull/5019
* chore: :arrow_up: Update ggml-org/llama.cpp to `f4c3dd5daa3a79f713813cf1aabdc5886071061d` by @localai-bot in https://github.com/mudler/LocalAI/pull/5022
* chore: :arrow_up: Update ggml-org/llama.cpp to `8ba95dca2065c0073698afdfcda4c8a8f08bf0d9` by @localai-bot in https://github.com/mudler/LocalAI/pull/5026
* chore: :arrow_up: Update ggml-org/llama.cpp to `b1b132efcba216c873715c483809730bb253f4a1` by @localai-bot in https://github.com/mudler/LocalAI/pull/5029
* chore: :arrow_up: Update ggml-org/llama.cpp to `d84635b1b085d54d6a21924e6171688d6e3dfb46` by @localai-bot in https://github.com/mudler/LocalAI/pull/5035
* chore: :arrow_up: Update ggml-org/llama.cpp to `568013d0cd3d5add37c376b3d5e959809b711fc7` by @localai-bot in https://github.com/mudler/LocalAI/pull/5042
* chore: :arrow_up: Update ggml-org/llama.cpp to `e04643063b3d240b8c0fdba98677dff6ba346784` by @localai-bot in https://github.com/mudler/LocalAI/pull/5047
* chore: :arrow_up: Update ggml-org/llama.cpp to `4375415b4abf94fb36a5fd15f233ac0ee23c0bd1` by @localai-bot in https://github.com/mudler/LocalAI/pull/5052
* chore: :arrow_up: Update ggml-org/llama.cpp to `ba932dfb50cc694645b1a148c72f8c06ee080b17` by @localai-bot in https://github.com/mudler/LocalAI/pull/5053
* chore: :arrow_up: Update ggml-org/llama.cpp to `77f9c6bbe55fccd9ea567794024cb80943947901` by @localai-bot in https://github.com/mudler/LocalAI/pull/5062
* chore: :arrow_up: Update ggml-org/llama.cpp to `c95fa362b3587d1822558f7e28414521075f254f` by @localai-bot in https://github.com/mudler/LocalAI/pull/5068
* chore: :arrow_up: Update ggml-org/llama.cpp to `ef19c71769681a0b3dde6bc90911728376e5d236` by @localai-bot in https://github.com/mudler/LocalAI/pull/5073
* chore: :arrow_up: Update ggml-org/llama.cpp to `b3298fa47a2d56ae892127ea038942ab1cada190` by @localai-bot in https://github.com/mudler/LocalAI/pull/5077
* chore: :arrow_up: Update ggml-org/llama.cpp to `5dec47dcd411fdf815a3708fd6194e2b13d19006` by @localai-bot in https://github.com/mudler/LocalAI/pull/5079
* chore: :arrow_up: Update ggml-org/llama.cpp to `b4ae50810e4304d052e630784c14bde7e79e4132` by @localai-bot in https://github.com/mudler/LocalAI/pull/5085
* chore: :arrow_up: Update ggml-org/llama.cpp to `0bb2919335d00ff0bc79d5015da95c422de51f03` by @localai-bot in https://github.com/mudler/LocalAI/pull/5095
* chore: :arrow_up: Update ggml-org/llama.cpp to `4663bd353c61c1136cd8a97b9908755e4ab30cec` by @localai-bot in https://github.com/mudler/LocalAI/pull/5100
### Other Changes
* docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/4834
* feat: improve ui models list in the index by @mudler in https://github.com/mudler/LocalAI/pull/4863
* fix(ui): not all models comes from gallery by @mudler in https://github.com/mudler/LocalAI/pull/4915
* Revert "chore(deps): Bump intel-extension-for-pytorch from 2.3.110+xpu to 2.6.10+xpu in /backend/python/diffusers" by @mudler in https://github.com/mudler/LocalAI/pull/4992
* chore(deps): Bump grpcio to 1.71.0 by @mudler in https://github.com/mudler/LocalAI/pull/4993
* fix: ensure git-lfs is present by @dave-gray101 in https://github.com/mudler/LocalAI/pull/5078

&lt;/details&gt;

&lt;h2&gt;New Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@bhulsken made their first contribution in https://github.com/mudler/LocalAI/pull/4837&lt;/li&gt;
&lt;li&gt;@TheDropZone made their first contribution in https://github.com/mudler/LocalAI/pull/4855&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Full Changelog&lt;/strong&gt;: https://github.com/mudler/LocalAI/compare/v2.26.0...v2.27.0&lt;/p&gt;</content>
    <link href="https://github.com/mudler/LocalAI/releases/tag/v2.27.0" rel="alternate"/>
  </entry>
  <entry>
    <id>https://github.com/mudler/LocalAI/releases/tag/v2.28.0</id>
    <title>New release for LocalAI: v2.28.0</title>
    <updated>2025-04-15T16:41:03-04:00</updated>
    <author>
      <name>mudler/LocalAI</name>
    </author>
    <content>&lt;h1&gt;🎉 LocalAI v2.28.0: New Look &amp;amp; The Rebirth of LocalAGI! 🎉&lt;/h1&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align="center"&gt;
      &lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/refs/heads/master/core/http/static/logo.png" width="300" alt="New LocalAI Logo"&gt;
      &lt;br&gt;
      &lt;em&gt;Our fresh new look!&lt;/em&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Big news, everyone! Not only does LocalAI have a brand new logo, but we're also celebrating the full rebirth of &lt;strong&gt;LocalAGI&lt;/strong&gt;, our powerful agent framework, now completely rewritten and ready to revolutionize your local AI workflows!&lt;/p&gt;
&lt;h2&gt;Rewinding the Clock: The Journey of LocalAI &amp;amp; LocalAGI&lt;/h2&gt;
&lt;p&gt;Two years ago, &lt;strong&gt;LocalAI&lt;/strong&gt; emerged as a pioneer in the local AI inferencing space, offering an OpenAI-compatible API layer long before it became common. Around the same time, &lt;strong&gt;LocalAGI&lt;/strong&gt; was born as an experiment in AI agent frameworks – you can even find the &lt;a href="https://x.com/mudler_it/status/1687938358079578113"&gt;original announcement here&lt;/a&gt;! Originally built in Python, it inspired many with its local-first approach.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;See LocalAGI (Original Python Version) in Action!&lt;/summary&gt;

*Searching the internet (interactive mode):*
&lt;video src="https://github.com/mudler/LocalAGI/assets/2420543/23199ca3-7380-4efc-9fac-a6bc2b52bdb3"&gt;&lt;/video&gt;

*Planning a road trip (batch mode):*
&lt;video src="https://github.com/mudler/LocalAGI/assets/2420543/9ba43b82-dec5-432a-bdb9-8318e7db59a4"&gt;&lt;/video&gt;

&lt;/details&gt;

&lt;p&gt;That early experiment has now evolved significantly!&lt;/p&gt;
&lt;h2&gt;Introducing LocalAGI v2: The Agent Framework Reborn in Go!&lt;/h2&gt;
&lt;p align="center"&gt;
  &lt;a href="https://github.com/mudler/LocalAGI" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo"&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;We're thrilled to announce that &lt;a href="https://github.com/mudler/LocalAGI"&gt;&lt;strong&gt;LocalAGI&lt;/strong&gt;&lt;/a&gt; has been rebuilt from the ground up in &lt;strong&gt;Golang&lt;/strong&gt;! It's now a modern, robust AI Agent Orchestration Platform designed to work seamlessly with LocalAI. Huge thanks to the community, especially @richiejp, for jumping in and helping create a fantastic new WebUI!&lt;/p&gt;
&lt;p&gt;LocalAGI leverages all the features that make LocalAI great for agentic tasks. During the refactor, we even spun out the memory layer into its own component: &lt;a href="https://github.com/mudler/LocalRecall?tab=readme-ov-file"&gt;&lt;strong&gt;LocalRecall&lt;/strong&gt;&lt;/a&gt;, a standalone REST API for persistent agent memory.&lt;/p&gt;
&lt;h3&gt;🚀 What Makes LocalAGI v2 Shine?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;🎯 OpenAI Responses API Compatible:&lt;/strong&gt; Integrates perfectly with LocalAI, acting as a drop-in replacement for cloud APIs, keeping your interactions local and secure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🤖 Next-Gen AI Agent Orchestration:&lt;/strong&gt; Easily configure, deploy, and manage teams of intelligent AI agents through an intuitive no-code web interface.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🛡️ Privacy-First by Design:&lt;/strong&gt; Everything runs locally. Your data &lt;em&gt;never&lt;/em&gt; leaves your hardware.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;📡 Instant Integrations:&lt;/strong&gt; Comes with built-in connectors for Slack, Telegram, Discord, GitHub Issues, IRC, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;⚡ Extensible and Multimodal:&lt;/strong&gt; Supports multiple models (text, vision) and custom actions, perfectly complementing your LocalAI setup.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;✨ Check out the new LocalAGI WebUI:&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Web UI Dashboard" src="https://github.com/user-attachments/assets/a40194f9-af3a-461f-8b39-5f4612fbf221" /&gt;
&lt;img alt="Web UI Agent Settings" src="https://github.com/user-attachments/assets/fb3c3e2a-cd53-4ca8-97aa-c5da51ff1f83" /&gt;
&lt;img alt="Web UI Create Group" src="https://github.com/user-attachments/assets/102189a2-0fba-4a1e-b0cb-f99268ef8062" /&gt;&lt;/p&gt;
&lt;h2&gt;What's New Specifically in LocalAI v2.28.0?&lt;/h2&gt;
&lt;p&gt;Beyond the rebranding and the major LocalAGI news, this LocalAI release also brings its own set of improvements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;🖼️ SYCL Support:&lt;/strong&gt; Added SYCL support for &lt;code&gt;stablediffusion.cpp&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;✨ WebUI Enhancements:&lt;/strong&gt; Continued improvements to the user interface.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🧠 Diffusers Updated:&lt;/strong&gt; Core diffusers library has been updated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;💡 Lumina Model Support:&lt;/strong&gt; Now supports the &lt;a href="https://huggingface.co/Alpha-VLLM/Lumina-Image-2.0"&gt;Lumina model family&lt;/a&gt; for generating stunning images!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🐛 Bug Fixes:&lt;/strong&gt; Resolved issues related to setting &lt;code&gt;LOCALAI_SINGLE_ACTIVE_BACKEND&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The Complete Local Stack for Privacy-First AI&lt;/h2&gt;
&lt;p&gt;With LocalAGI rejoining LocalAI alongside LocalRecall, our ecosystem provides a complete, open-source stack for private, secure, and intelligent AI operations:&lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalAI"&gt;
        &lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/refs/heads/master/core/http/static/logo.png" width="200" alt="LocalAI Logo"&gt;
        &lt;h3&gt;LocalAI&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;The free, Open Source OpenAI alternative. Acts as a drop-in replacement REST API compatible with OpenAI specifications for local AI inferencing. No GPU required.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalAI"&gt;https://github.com/mudler/LocalAI&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalAGI"&gt;
         &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="200" alt="LocalAGI Logo"&gt;
         &lt;h3&gt;LocalAGI&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;A powerful Local AI agent management platform. Serves as a drop-in replacement for OpenAI's Responses API, supercharged with advanced agentic capabilities and a no-code UI.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalRecall"&gt;
         &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="200" alt="LocalRecall Logo"&gt;
         &lt;h3&gt;LocalRecall&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;A RESTful API and knowledge base management system providing persistent memory and storage capabilities for AI agents. Designed to work alongside LocalAI and LocalAGI.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt;https://github.com/mudler/LocalRecall&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2&gt;Join the Movement! ❤️&lt;/h2&gt;
&lt;p&gt;A massive &lt;strong&gt;THANK YOU&lt;/strong&gt; to our incredible community! LocalAI has over &lt;strong&gt;31,800 stars&lt;/strong&gt;, and LocalAGI has already rocketed past &lt;strong&gt;450+ stars&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;As a reminder, LocalAI is real FOSS (Free and Open Source Software) and its sibling projects are community-driven and not backed by VCs or a company. We rely on contributors donating their spare time. If you love open-source, privacy-first AI, please consider starring the repos, contributing code, reporting bugs, or spreading the word!&lt;/p&gt;
&lt;p&gt;👉 &lt;strong&gt;Check out the reborn LocalAGI v2 today:&lt;/strong&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let's continue building the future of AI, together! 🙌&lt;/p&gt;
&lt;h2&gt;Full changelog :point_down:&lt;/h2&gt;
&lt;details&gt;

&lt;summary&gt;
:point_right: Click to expand :point_left: 
&lt;/summary&gt;

## What's Changed
### Bug fixes :bug:
* fix(stablediffusion): Avoid GGML commit which causes CUDA compile error by @richiejp in https://github.com/mudler/LocalAI/pull/5170
### Exciting New Features 🎉
* feat(loader): enhance single active backend by treating as singleton by @mudler in https://github.com/mudler/LocalAI/pull/5107
### 🧠 Models
* chore(model gallery): add all-hands_openhands-lm-32b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/5111
* chore(model gallery): add burtenshaw_gemmacoder3-12b by @mudler in https://github.com/mudler/LocalAI/pull/5112
* chore(model gallery): add all-hands_openhands-lm-7b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/5113
* chore(model gallery): add all-hands_openhands-lm-1.5b-v0.1 by @mudler in https://github.com/mudler/LocalAI/pull/5114
* chore(model gallery): add gemma-3-12b-it-qat by @mudler in https://github.com/mudler/LocalAI/pull/5117
* chore(model gallery): add gemma-3-4b-it-qat by @mudler in https://github.com/mudler/LocalAI/pull/5118
* chore(model gallery): add tesslate_synthia-s1-27b by @mudler in https://github.com/mudler/LocalAI/pull/5119
* chore(model gallery): add katanemo_arch-function-chat-7b by @mudler in https://github.com/mudler/LocalAI/pull/5120
* chore(model gallery): add katanemo_arch-function-chat-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/5121
* chore(model gallery): add katanemo_arch-function-chat-3b by @mudler in https://github.com/mudler/LocalAI/pull/5122
* chore(model gallery): add gemma-3-27b-it-qat by @mudler in https://github.com/mudler/LocalAI/pull/5124
* chore(model gallery): add open-thoughts_openthinker2-32b by @mudler in https://github.com/mudler/LocalAI/pull/5128
* chore(model gallery): add open-thoughts_openthinker2-7b by @mudler in https://github.com/mudler/LocalAI/pull/5129
* chore(model gallery): add arliai_qwq-32b-arliai-rpr-v by @mudler in https://github.com/mudler/LocalAI/pull/5137
* chore(model gallery): add watt-ai_watt-tool-70b by @mudler in https://github.com/mudler/LocalAI/pull/5138
* chore(model gallery): add eurydice-24b-v2-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5139
* chore(model gallery): add mensa-beta-14b-instruct-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5140
* chore(model gallery): add meta-llama_llama-4-scout-17b-16e-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5141
* fix(gemma): improve prompt for tool calls by @mudler in https://github.com/mudler/LocalAI/pull/5142
* chore(model gallery): add cogito-v1-preview-qwen-14b by @mudler in https://github.com/mudler/LocalAI/pull/5145
* chore(model gallery): add deepcogito_cogito-v1-preview-llama-8b by @mudler in https://github.com/mudler/LocalAI/pull/5147
* chore(model gallery): add deepcogito_cogito-v1-preview-llama-3b by @mudler in https://github.com/mudler/LocalAI/pull/5148
* chore(model gallery): add deepcogito_cogito-v1-preview-qwen-32b by @mudler in https://github.com/mudler/LocalAI/pull/5149
* chore(model gallery): add deepcogito_cogito-v1-preview-llama-70b by @mudler in https://github.com/mudler/LocalAI/pull/5150
* chore(model gallery): add agentica-org_deepcoder-14b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5151
* chore(model gallery): add trappu_magnum-picaro-0.7-v2-12b by @mudler in https://github.com/mudler/LocalAI/pull/5153
* chore(model gallery): add soob3123_amoral-cogito-v1-preview-qwen-14b by @mudler in https://github.com/mudler/LocalAI/pull/5154
* chore(model gallery): add agentica-org_deepcoder-1.5b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5156
* chore(model gallery): add zyphra_zr1-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/5157
* chore(model gallery): add tesslate_gradience-t1-3b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5160
* chore(model gallery): add lightthinker-qwen by @mudler in https://github.com/mudler/LocalAI/pull/5165
* chore(model gallery): add mag-picaro-72b by @mudler in https://github.com/mudler/LocalAI/pull/5166
* chore(model gallery): add hamanasu-adventure-4b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5167
* chore(model gallery): add hamanasu-magnum-4b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5168
* chore(model gallery): add daichi-12b by @mudler in https://github.com/mudler/LocalAI/pull/5169
* chore(model gallery): add skywork_skywork-or1-7b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5173
* chore(model gallery): add skywork_skywork-or1-math-7b by @mudler in https://github.com/mudler/LocalAI/pull/5174
* chore(model gallery): add skywork_skywork-or1-32b-preview by @mudler in https://github.com/mudler/LocalAI/pull/5175
* chore(model gallery): add nvidia_llama-3.1-8b-ultralong-1m-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5176
* chore(model gallery): add nvidia_llama-3.1-8b-ultralong-4m-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5177
* chore(model gallery): add m1-32b by @mudler in https://github.com/mudler/LocalAI/pull/5182
### 📖 Documentation and examples
* Update README.md by @qwerty108109 in https://github.com/mudler/LocalAI/pull/5172
* Rebrand: the LocalAI stack family by @mudler in https://github.com/mudler/LocalAI/pull/5159
### 👒 Dependencies
* chore: :arrow_up: Update ggml-org/llama.cpp to `c80a7759dab10657b9b6c3e87eef988a133b9b6a` by @localai-bot in https://github.com/mudler/LocalAI/pull/5105
* chore: :arrow_up: Update ggml-org/llama.cpp to `f423981ac806bf031d83784bcb47d2721bc70f97` by @localai-bot in https://github.com/mudler/LocalAI/pull/5108
* chore(deps): bump llama.cpp to 'f01bd02376f919b05ee635f438311be8dfc91d7c by @mudler in https://github.com/mudler/LocalAI/pull/5110
* fix(sycl): kernel not found error by forcing -fsycl by @richiejp in https://github.com/mudler/LocalAI/pull/5115
* chore: :arrow_up: Update ggml-org/llama.cpp to `c262beddf29f3f3be5bbbf167b56029a19876956` by @localai-bot in https://github.com/mudler/LocalAI/pull/5116
* chore: :arrow_up: Update ggml-org/llama.cpp to `3e1d29348b5d77269f6931500dd1c1a729d429c8` by @localai-bot in https://github.com/mudler/LocalAI/pull/5123
* chore: :arrow_up: Update ggml-org/llama.cpp to `6bf28f0111ff9f21b3c1b1eace20c590281e7ba6` by @mudler in https://github.com/mudler/LocalAI/pull/5127
* chore: :arrow_up: Update ggml-org/llama.cpp to `916c83bfe7f8b08ada609c3b8e583cf5301e594b` by @localai-bot in https://github.com/mudler/LocalAI/pull/5130
* chore(deps): bump securego/gosec from 2.22.0 to 2.22.3 by @dependabot in https://github.com/mudler/LocalAI/pull/5134
* chore(deps): bump llama.cpp to `4ccea213bc629c4eef7b520f7f6c59ce9bbdaca0` by @mudler in https://github.com/mudler/LocalAI/pull/5143
* chore: :arrow_up: Update ggml-org/llama.cpp to `b32efad2bc42460637c3a364c9554ea8217b3d7f` by @localai-bot in https://github.com/mudler/LocalAI/pull/5146
* chore: :arrow_up: Update ggml-org/llama.cpp to `d3bd7193ba66c15963fd1c59448f22019a8caf6e` by @localai-bot in https://github.com/mudler/LocalAI/pull/5152
* chore: :arrow_up: Update ggml-org/llama.cpp to `64eda5deb9859e87a020e56bab5d2f9ca956f1de` by @localai-bot in https://github.com/mudler/LocalAI/pull/5155
* chore: :arrow_up: Update ggml-org/llama.cpp to `bc091a4dc585af25c438c8473285a8cfec5c7695` by @localai-bot in https://github.com/mudler/LocalAI/pull/5158
* chore: :arrow_up: Update ggml-org/llama.cpp to `71e90e8813f90097701e62f7fce137d96ddf41e2` by @localai-bot in https://github.com/mudler/LocalAI/pull/5171
* chore: :arrow_up: Update ggml-org/llama.cpp to `d6d2c2ab8c8865784ba9fef37f2b2de3f2134d33` by @localai-bot in https://github.com/mudler/LocalAI/pull/5178
* fix(stablediffusion): Pass ROCM LD CGO flags through to recursive make by @richiejp in https://github.com/mudler/LocalAI/pull/5179
### Other Changes
* docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/5104
* chore: drop remoteLibraryURL from kong vars by @mudler in https://github.com/mudler/LocalAI/pull/5103
* fix: race during stop of active backends by @mudler in https://github.com/mudler/LocalAI/pull/5106
* fix(webui): improve model display, do not block view by @mudler in https://github.com/mudler/LocalAI/pull/5133
* feat(diffusers): add support for Lumina2Text2ImgPipeline by @mudler in https://github.com/mudler/LocalAI/pull/4806
* feat(stablediffusion): Enable SYCL by @richiejp in https://github.com/mudler/LocalAI/pull/5144
* fix(stablediffusion): Avoid overwriting SYCL specific flags from outer make call by @richiejp in https://github.com/mudler/LocalAI/pull/5181

## New Contributors
* @qwerty108109 made their first contribution in https://github.com/mudler/LocalAI/pull/5172

&lt;/details&gt;

&lt;p&gt;&lt;strong&gt;Full Changelog&lt;/strong&gt;: https://github.com/mudler/LocalAI/compare/v2.27.0...v2.28.0&lt;/p&gt;</content>
    <link href="https://github.com/mudler/LocalAI/releases/tag/v2.28.0" rel="alternate"/>
  </entry>
  <entry>
    <id>https://github.com/mudler/LocalAI/releases/tag/v2.29.0</id>
    <title>New release for LocalAI: v2.29.0</title>
    <updated>2025-05-12T16:31:20-04:00</updated>
    <author>
      <name>mudler/LocalAI</name>
    </author>
    <content>&lt;h1 align="center"&gt;
  &lt;br&gt;
  &lt;img height="300" src="https://raw.githubusercontent.com/mudler/LocalAI/refs/heads/master/core/http/static/logo.png"&gt; &lt;br&gt;
&lt;br&gt;
v2.29.0
&lt;/h1&gt;

&lt;p&gt;I am thrilled to announce the release of LocalAI v2.29.0! This update focuses heavily on refining our container image strategy, making default images leaner and providing clearer options for users needing specific features or hardware acceleration. We've also added support for new models like Qwen3, enhanced existing backends, and introduced experimental endpoints, like video generation!&lt;/p&gt;
&lt;h2&gt;⚠️ Important: Breaking Changes&lt;/h2&gt;
&lt;p&gt;This release includes significant changes to container image tagging and contents. Please review carefully:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Python Dependencies Moved:&lt;/strong&gt; Images containing extra Python dependencies (like those for &lt;code&gt;diffusers&lt;/code&gt;) now require the &lt;code&gt;-extras&lt;/code&gt; suffix (e.g., &lt;code&gt;latest-gpu-nvidia-cuda-12-extras&lt;/code&gt;). Default images are now slimmer and do &lt;em&gt;not&lt;/em&gt; include these dependencies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FFmpeg is Now Standard:&lt;/strong&gt; All core images now include FFmpeg. The separate &lt;code&gt;-ffmpeg&lt;/code&gt; tags have been removed. If you previously used an &lt;code&gt;-ffmpeg&lt;/code&gt; tagged image, simply switch to the corresponding base image tag (e.g., &lt;code&gt;latest-gpu-hipblas-ffmpeg&lt;/code&gt; becomes &lt;code&gt;latest-gpu-hipblas&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here below some examples, note that the CI is still publishing the images so won't be available until jobs are processed, and the installation scripts will be updated right after images are publicly available.&lt;/p&gt;
&lt;h3&gt;CPU only image:&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;NVIDIA GPU Images:&lt;/h3&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1&gt;CUDA 12.0 with core features&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12&lt;/p&gt;
&lt;h1&gt;CUDA 12.0 with extra Python dependencies&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12-extras&lt;/p&gt;
&lt;h1&gt;CUDA 11.7 with core features&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11&lt;/p&gt;
&lt;h1&gt;CUDA 11.7 with extra Python dependencies&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11-extras&lt;/p&gt;
&lt;h1&gt;NVIDIA Jetson (L4T) ARM64&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```&lt;/p&gt;
&lt;h3&gt;AMD GPU Images (ROCm):&lt;/h3&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1&gt;ROCm with core features&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas&lt;/p&gt;
&lt;h1&gt;ROCm with extra Python dependencies&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas-extras
```&lt;/p&gt;
&lt;h3&gt;Intel GPU Images (oneAPI):&lt;/h3&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1&gt;Intel GPU with FP16 support&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f16&lt;/p&gt;
&lt;h1&gt;Intel GPU with FP16 support and extra dependencies&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f16-extras&lt;/p&gt;
&lt;h1&gt;Intel GPU with FP32 support&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f32&lt;/p&gt;
&lt;h1&gt;Intel GPU with FP32 support and extra dependencies&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-intel-f32-extras
```&lt;/p&gt;
&lt;h3&gt;Vulkan GPU Images:&lt;/h3&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1&gt;Vulkan with core features&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```&lt;/p&gt;
&lt;h3&gt;AIO Images (pre-downloaded models):&lt;/h3&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1&gt;CPU version&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu&lt;/p&gt;
&lt;h1&gt;NVIDIA CUDA 12 version&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12&lt;/p&gt;
&lt;h1&gt;NVIDIA CUDA 11 version&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11&lt;/p&gt;
&lt;h1&gt;Intel GPU version&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel-f16&lt;/p&gt;
&lt;h1&gt;AMD GPU version&lt;/h1&gt;
&lt;p&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```&lt;/p&gt;
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Key Changes in v2.29.0&lt;/h2&gt;
&lt;h3&gt;📦 Container Image Overhaul&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;-extras&lt;/code&gt; Suffix:&lt;/strong&gt; Images with additional Python dependencies are now identified by the &lt;code&gt;-extras&lt;/code&gt; suffix.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Default Images:&lt;/strong&gt; Standard tags (like &lt;code&gt;latest&lt;/code&gt;, &lt;code&gt;latest-gpu-nvidia-cuda-12&lt;/code&gt;) now provide core LocalAI functionality without the extra Python libraries.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FFmpeg Inclusion:&lt;/strong&gt; FFmpeg is bundled in all images, simplifying setup for multimedia tasks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New &lt;code&gt;latest-*&lt;/code&gt; Tags:&lt;/strong&gt; Added specific &lt;code&gt;latest&lt;/code&gt; tags for various GPU architectures:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;latest-gpu-hipblas&lt;/code&gt; (AMD ROCm)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;latest-gpu-intel-f16&lt;/code&gt; (Intel oneAPI FP16)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;latest-gpu-intel-f32&lt;/code&gt; (Intel oneAPI FP32)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;latest-gpu-nvidia-cuda-12&lt;/code&gt; (NVIDIA CUDA 12)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;latest-gpu-vulkan&lt;/code&gt; (Vulkan)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;🚀 New Features &amp;amp; Enhancements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Qwen3 Model Support:&lt;/strong&gt; Officially integrated support for the Qwen3 model family.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experimental Auto GPU Offload:&lt;/strong&gt; LocalAI can now attempt to automatically detect GPUs and configure optimal layer offloading for &lt;code&gt;llama.cpp&lt;/code&gt; and &lt;code&gt;CLIP&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Whisper.cpp GPU Acceleration:&lt;/strong&gt; Updated whisper.cpp and enabled GPU support via cuBLAS (NVIDIA) and Vulkan. SYCL and Hipblas support are in progress.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experimental Video Generation:&lt;/strong&gt; Introduced a &lt;code&gt;/video/generations&lt;/code&gt; endpoint. Stay tuned for compatible model backends!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Installer Uninstall Option:&lt;/strong&gt; The &lt;code&gt;install.sh&lt;/code&gt; script now includes a &lt;code&gt;--uninstall&lt;/code&gt; flag for easy removal.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Expanded Hipblas Targets:&lt;/strong&gt; Added support for a wider range of AMD GPU architectures. &lt;code&gt;gfx803,gfx900,gfx906,gfx908,gfx90a,gfx942,gfx1010,gfx1030,gfx1032,gfx1100,gfx1101,gfx1102&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;🧹 Backend Updates&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;AutoGPTQ Backend Removed:&lt;/strong&gt; This backend has been dropped due to being discontinued upstream.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt; experimental support to automatically detect GPU layers offloading.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The Complete Local Stack for Privacy-First AI&lt;/h2&gt;
&lt;p&gt;With LocalAGI rejoining LocalAI alongside LocalRecall, our ecosystem provides a complete, open-source stack for private, secure, and intelligent AI operations:&lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalAI"&gt;
        &lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/refs/heads/master/core/http/static/logo.png" width="200" alt="LocalAI Logo"&gt;
        &lt;h3&gt;LocalAI&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;The free, Open Source OpenAI alternative. Acts as a drop-in replacement REST API compatible with OpenAI specifications for local AI inferencing. No GPU required.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalAI"&gt;https://github.com/mudler/LocalAI&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalAGI"&gt;
         &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="200" alt="LocalAGI Logo"&gt;
         &lt;h3&gt;LocalAGI&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;A powerful Local AI agent management platform. Serves as a drop-in replacement for OpenAI's Responses API, supercharged with advanced agentic capabilities and a no-code UI.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width="30%" valign="top" align="center"&gt;
      &lt;a href="https://github.com/mudler/LocalRecall"&gt;
         &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="200" alt="LocalRecall Logo"&gt;
         &lt;h3&gt;LocalRecall&lt;/h3&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width="70%" valign="top"&gt;
      &lt;p&gt;A RESTful API and knowledge base management system providing persistent memory and storage capabilities for AI agents. Designed to work alongside LocalAI and LocalAGI.&lt;/p&gt;
      &lt;p&gt;&lt;em&gt;Link:&lt;/em&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt;https://github.com/mudler/LocalRecall&lt;/a&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h2&gt;Join the Movement! ❤️&lt;/h2&gt;
&lt;p&gt;A massive &lt;strong&gt;THANK YOU&lt;/strong&gt; to our incredible community! LocalAI has over &lt;strong&gt;32,500 stars&lt;/strong&gt;, and LocalAGI has already rocketed past &lt;strong&gt;650+ stars&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;As a reminder, LocalAI is real FOSS (Free and Open Source Software) and its sibling projects are community-driven and not backed by VCs or a company. We rely on contributors donating their spare time. If you love open-source, privacy-first AI, please consider starring the repos, contributing code, reporting bugs, or spreading the word!&lt;/p&gt;
&lt;p&gt;👉 &lt;strong&gt;Check out the reborn LocalAGI v2 today:&lt;/strong&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let's continue building the future of AI, together! 🙌&lt;/p&gt;
&lt;h2&gt;Full changelog :point_down:&lt;/h2&gt;
&lt;details&gt;

&lt;summary&gt;
:point_right: Click to expand :point_left: 
&lt;/summary&gt;

## What's Changed
### Breaking Changes 🛠
* chore(autogptq): drop archived backend by @mudler in https://github.com/mudler/LocalAI/pull/5214
* chore(ci): build only images with ffmpeg included, simplify tags by @mudler in https://github.com/mudler/LocalAI/pull/5251
* chore(ci): strip 'core' in the image suffix, identify python-based images with 'extras' by @mudler in https://github.com/mudler/LocalAI/pull/5353
### Bug fixes :bug:
* fix: bark-cpp: assign FLAG_TTS to bark-cpp backend by @M0Rf30 in https://github.com/mudler/LocalAI/pull/5186
* fix(talk): Talk interface sends content-type headers to chatgpt by @baflo in https://github.com/mudler/LocalAI/pull/5200
* fix: installation script compatibility with fedora 41 and later, fedora headless unclear errors by @Bloodis94 in https://github.com/mudler/LocalAI/pull/5239
* fix(stablediffusion-ggml): Build with DSD CUDA, HIP and Metal flags by @richiejp in https://github.com/mudler/LocalAI/pull/5236
* fix(install/gpu):Fix docker not being able to leverage the GPU on systems that have SELinux Enforced by @Bloodis94 in https://github.com/mudler/LocalAI/pull/5252
* fix(aio): Fix copypasta in download files for gpt-4 model by @richiejp in https://github.com/mudler/LocalAI/pull/5276
* fix(diffusers): consider options only in form of key/value by @mudler in https://github.com/mudler/LocalAI/pull/5277
* fix(gpu): do not assume gpu being returned has node and mem by @mudler in https://github.com/mudler/LocalAI/pull/5310
* fix(hipblas): do not build all cpu-specific flags by @mudler in https://github.com/mudler/LocalAI/pull/5322
### Exciting New Features 🎉
* chore(ci): add latest images for core by @mudler in https://github.com/mudler/LocalAI/pull/5198
* feat(install.sh): allow to uninstall with --uninstall by @mudler in https://github.com/mudler/LocalAI/pull/5202
* chore: bump grpc limits to 50MB by @mudler in https://github.com/mudler/LocalAI/pull/5212
* feat(llama.cpp/clip): inject gpu options if we detect GPUs by @mudler in https://github.com/mudler/LocalAI/pull/5243
* feat(install): added complete process for installing nvidia drivers on fedora without pulling X11 by @Bloodis94 in https://github.com/mudler/LocalAI/pull/5246
* feat(video-gen): add endpoint for video generation by @mudler in https://github.com/mudler/LocalAI/pull/5247
* feat(llama.cpp): estimate vram usage by @mudler in https://github.com/mudler/LocalAI/pull/5299
* chore(defaults): enlarge defaults, drop gpu layers which is infered by @mudler in https://github.com/mudler/LocalAI/pull/5308
* fix(arm64): do not build instructions which are not available by @mudler in https://github.com/mudler/LocalAI/pull/5318
* feat(whisper.cpp): gpu support by @mudler in https://github.com/mudler/LocalAI/pull/5344
### 🧠 Models
* chore(model gallery): add suno-ai bark-cpp model by @M0Rf30 in https://github.com/mudler/LocalAI/pull/5187
* chore(model gallery): add menlo_rezero-v0.1-llama-3.2-3b-it-grpo-250404 by @mudler in https://github.com/mudler/LocalAI/pull/5194
* chore(model gallery): add thedrummer_rivermind-12b-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5195
* chore(model gallery): add dreamgen_lucid-v1-nemo by @mudler in https://github.com/mudler/LocalAI/pull/5196
* chore(model gallery): add qwen2.5-14b-instruct-1m by @mudler in https://github.com/mudler/LocalAI/pull/5201
* chore(model gallery): add ibm-granite_granite-3.3-8b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5204
* chore(model gallery): add ibm-granite_granite-3.3-2b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5205
* chore(model gallery): add readyart_amoral-fallen-omega-gemma3-12b by @mudler in https://github.com/mudler/LocalAI/pull/5206
* chore(model gallery): add google-gemma-3-27b-it-qat-q4_0-small by @mudler in https://github.com/mudler/LocalAI/pull/5207
* chore(model gallery): add pictor-1338-qwenp-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/5208
* chore(model gallery) add llama_3.3_70b_darkhorse-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5222
* chore(model gallery) add amoral-gemma3-1b-v2 by @mudler in https://github.com/mudler/LocalAI/pull/5223
* chore(model gallery): add starrysky-12b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5224
* chore(model gallery): add soob3123_veritas-12b by @mudler in https://github.com/mudler/LocalAI/pull/5241
* chore(model gallery): add l3.3-geneticlemonade-unleashed-v2-70b by @mudler in https://github.com/mudler/LocalAI/pull/5249
* chore(model gallery): add l3.3-genetic-lemonade-sunset-70b by @mudler in https://github.com/mudler/LocalAI/pull/5250
* chore(model gallery): add nvidia_openmath-nemotron-32b by @mudler in https://github.com/mudler/LocalAI/pull/5260
* chore(model gallery): add nvidia_openmath-nemotron-1.5b by @mudler in https://github.com/mudler/LocalAI/pull/5261
* chore(model gallery): add nvidia_openmath-nemotron-7b by @mudler in https://github.com/mudler/LocalAI/pull/5262
* chore(model gallery): add nvidia_openmath-nemotron-14b by @mudler in https://github.com/mudler/LocalAI/pull/5263
* chore(model gallery): add nvidia_openmath-nemotron-14b-kaggle by @mudler in https://github.com/mudler/LocalAI/pull/5264
* chore(model gallery): add qwen3-30b-a3b by @mudler in https://github.com/mudler/LocalAI/pull/5269
* chore(model gallery): add qwen3-32b by @mudler in https://github.com/mudler/LocalAI/pull/5270
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/5268
* chore(model gallery): add qwen3-14b by @mudler in https://github.com/mudler/LocalAI/pull/5271
* chore(model gallery): add qwen3-8b by @mudler in https://github.com/mudler/LocalAI/pull/5272
* chore(model gallery): add qwen3-4b by @mudler in https://github.com/mudler/LocalAI/pull/5273
* chore(model gallery): add qwen3-1.7b by @mudler in https://github.com/mudler/LocalAI/pull/5274
* chore(model gallery): add qwen3-0.6b by @mudler in https://github.com/mudler/LocalAI/pull/5275
* chore(model gallery): add mlabonne_qwen3-14b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5281
* chore(model gallery): add mlabonne_qwen3-8b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5282
* chore(model gallery): add mlabonne_qwen3-4b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5283
* chore(model gallery): add qwen3-30b-a3b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5285
* chore(model gallery): add qwen3-8b-jailbroken by @mudler in https://github.com/mudler/LocalAI/pull/5286
* chore(model gallery): add fast-math-qwen3-14b by @mudler in https://github.com/mudler/LocalAI/pull/5287
* chore(model gallery): add microsoft_phi-4-mini-reasoning by @mudler in https://github.com/mudler/LocalAI/pull/5288
* chore(model gallery): add josiefied-qwen3-8b-abliterated-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5293
* chore(model gallery): add furina-8b by @mudler in https://github.com/mudler/LocalAI/pull/5294
* chore(model gallery): add microsoft_phi-4-reasoning-plus by @mudler in https://github.com/mudler/LocalAI/pull/5295
* chore(model gallery): add microsoft_phi-4-reasoning by @mudler in https://github.com/mudler/LocalAI/pull/5296
* chore(model gallery): add shuttleai_shuttle-3.5 by @mudler in https://github.com/mudler/LocalAI/pull/5297
* chore(model gallery): add webthinker-qwq-32b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5298
* chore(model gallery): add planetoid_27b_v.2 by @mudler in https://github.com/mudler/LocalAI/pull/5301
* chore(model gallery): add genericrpv3-4b by @mudler in https://github.com/mudler/LocalAI/pull/5302
* chore(model gallery): add comet_12b_v.5-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5303
* chore(model gallery): add amoral-qwen3-14b by @mudler in https://github.com/mudler/LocalAI/pull/5304
* chore(model gallery): add qwen-3-32b-medical-reasoning-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5305
* chore(model gallery): add smoothie-qwen3-8b by @mudler in https://github.com/mudler/LocalAI/pull/5306
* chore(model gallery): add qwen3-30b-a1.5b-high-speed by @mudler in https://github.com/mudler/LocalAI/pull/5311
* chore(model gallery): add kalomaze_qwen3-16b-a3b by @mudler in https://github.com/mudler/LocalAI/pull/5312
* chore(model gallery): add rei-v3-kto-12b by @mudler in https://github.com/mudler/LocalAI/pull/5313
* chore(model gallery): add allura-org_remnant-qwen3-8b by @mudler in https://github.com/mudler/LocalAI/pull/5317
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/5321
* chore(model gallery): add huihui-ai_qwen3-14b-abliterated by @mudler in https://github.com/mudler/LocalAI/pull/5324
* chore(model gallery): add goekdeniz-guelmez_josiefied-qwen3-8b-abliterated-v1 by @mudler in https://github.com/mudler/LocalAI/pull/5325
* chore(model gallery): add claria-14b by @mudler in https://github.com/mudler/LocalAI/pull/5326
* chore(model gallery): add qwen3-14b-griffon-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5330
* chore(model gallery): add qwen3-4b-esper3-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5332
* chore(model gallery): add servicenow-ai_apriel-nemotron-15b-thinker by @mudler in https://github.com/mudler/LocalAI/pull/5333
* chore(model gallery): add cognition-ai_kevin-32b by @mudler in https://github.com/mudler/LocalAI/pull/5334
* chore(model gallery): add qwen3-14b-uncensored by @mudler in https://github.com/mudler/LocalAI/pull/5335
* chore(model gallery): add symiotic-14b-i1 by @mudler in https://github.com/mudler/LocalAI/pull/5336
* chore(model gallery): add gemma-3-12b-fornaxv.2-qat-cot by @mudler in https://github.com/mudler/LocalAI/pull/5337
* chore(model-gallery): :arrow_up: update checksum by @localai-bot in https://github.com/mudler/LocalAI/pull/5346
* chore(model gallery): add gryphe_pantheon-proto-rp-1.8-30b-a3b by @mudler in https://github.com/mudler/LocalAI/pull/5347
* chore(model gallery): add qwen_qwen2.5-vl-7b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5348
* chore(model gallery): add qwen_qwen2.5-vl-72b-instruct by @mudler in https://github.com/mudler/LocalAI/pull/5349
### 📖 Documentation and examples
* chore(docs): improve installer.sh docs by @mudler in https://github.com/mudler/LocalAI/pull/5232
* docs(Vulkan): Add GPU docker documentation for Vulkan by @sredman in https://github.com/mudler/LocalAI/pull/5255
* docs: update docs for DisableWebUI flag by @Mohit-Gaur in https://github.com/mudler/LocalAI/pull/5256
* fix(CUDA):Add note for how to run CUDA with SELinux by @sredman in https://github.com/mudler/LocalAI/pull/5259
### 👒 Dependencies
* chore: :arrow_up: Update ggml-org/llama.cpp to `80f19b41869728eeb6a26569957b92a773a2b2c6` by @localai-bot in https://github.com/mudler/LocalAI/pull/5183
* chore: :arrow_up: Update ggml-org/llama.cpp to `015022bb53387baa8b23817ac03743705c7d472b` by @localai-bot in https://github.com/mudler/LocalAI/pull/5192
* chore: :arrow_up: Update ggml-org/llama.cpp to `2f74c354c0f752ed9aabf7d3a350e6edebd7e744` by @localai-bot in https://github.com/mudler/LocalAI/pull/5203
* chore: :arrow_up: Update ggml-org/llama.cpp to `6408210082cc0a61b992b487be7e2ff2efbb9e36` by @localai-bot in https://github.com/mudler/LocalAI/pull/5211
* chore: :arrow_up: Update ggml-org/llama.cpp to `00137157fca3d17b90380762b4d7cc158d385bd3` by @localai-bot in https://github.com/mudler/LocalAI/pull/5218
* chore: :arrow_up: Update ggml-org/llama.cpp to `6602304814e679cc8c162bb760a034aceb4f8965` by @localai-bot in https://github.com/mudler/LocalAI/pull/5228
* chore: :arrow_up: Update ggml-org/llama.cpp to `1d735c0b4fa0551c51c2f4ac888dd9a01f447985` by @localai-bot in https://github.com/mudler/LocalAI/pull/5233
* chore(deps): bump mxschmitt/action-tmate from 3.19 to 3.21 by @dependabot in https://github.com/mudler/LocalAI/pull/5231
* chore: :arrow_up: Update ggml-org/llama.cpp to `658987cfc9d752dca7758987390d5fb1a7a0a54a` by @localai-bot in https://github.com/mudler/LocalAI/pull/5234
* chore: :arrow_up: Update ggml-org/llama.cpp to `ecda2ec4b347031a9b8a89ee2efc664ce63f599c` by @localai-bot in https://github.com/mudler/LocalAI/pull/5238
* chore: :arrow_up: Update ggml-org/llama.cpp to `226251ed56b85190e18a1cca963c45b888f4953c` by @localai-bot in https://github.com/mudler/LocalAI/pull/5240
* chore: :arrow_up: Update ggml-org/llama.cpp to `295354ea6848a77bdee204ee1c971d9b92ffcca9` by @localai-bot in https://github.com/mudler/LocalAI/pull/5245
* chore: :arrow_up: Update ggml-org/llama.cpp to `77d5e9a76a7b4a8a7c5bf9cf6ebef91860123cba` by @localai-bot in https://github.com/mudler/LocalAI/pull/5254
* chore: :arrow_up: Update ggml-org/llama.cpp to `ced44be34290fab450f8344efa047d8a08e723b4` by @localai-bot in https://github.com/mudler/LocalAI/pull/5258
* chore(deps): bump appleboy/scp-action from 0.1.7 to 1.0.0 by @dependabot in https://github.com/mudler/LocalAI/pull/5265
* chore: :arrow_up: Update ggml-org/llama.cpp to `5f5e39e1ba5dbea814e41f2a15e035d749a520bc` by @localai-bot in https://github.com/mudler/LocalAI/pull/5267
* chore: :arrow_up: Update ggml-org/llama.cpp to `e2e1ddb93a01ce282e304431b37e60b3cddb6114` by @localai-bot in https://github.com/mudler/LocalAI/pull/5278
* fix: vllm missing logprobs by @wyattearp in https://github.com/mudler/LocalAI/pull/5279
* chore: :arrow_up: Update ggml-org/llama.cpp to `3e168bede4d27b35656ab8026015b87659ecbec2` by @localai-bot in https://github.com/mudler/LocalAI/pull/5284
* chore: :arrow_up: Update ggml-org/llama.cpp to `d7a14c42a1883a34a6553cbfe30da1e1b84dfd6a` by @localai-bot in https://github.com/mudler/LocalAI/pull/5292
* chore(deps): bump llama.cpp to '1d36b3670b285e69e58b9d687c770a2a0a192194 by @mudler in https://github.com/mudler/LocalAI/pull/5307
* chore: :arrow_up: Update ggml-org/llama.cpp to `36667c8edcded08063ed51c7d57e9e086bbfc903` by @localai-bot in https://github.com/mudler/LocalAI/pull/5300
* fix: use rice when embedding large binaries by @mudler in https://github.com/mudler/LocalAI/pull/5309
* chore: :arrow_up: Update ggml-org/llama.cpp to `9fdfcdaeddd1ef57c6d041b89cd8fb7048a0f028` by @localai-bot in https://github.com/mudler/LocalAI/pull/5316
* chore(deps): bump mxschmitt/action-tmate from 3.21 to 3.22 by @dependabot in https://github.com/mudler/LocalAI/pull/5319
* chore(deps): bump llama.cpp to `b34c859146630dff136943abc9852ca173a7c9d6` by @mudler in https://github.com/mudler/LocalAI/pull/5323
* chore: :arrow_up: Update ggml-org/llama.cpp to `91a86a6f354aa73a7aab7bc3d283be410fdc93a5` by @localai-bot in https://github.com/mudler/LocalAI/pull/5329
* chore: :arrow_up: Update ggml-org/llama.cpp to `814f795e063c257f33b921eab4073484238a151a` by @localai-bot in https://github.com/mudler/LocalAI/pull/5331
* chore: :arrow_up: Update ggml-org/llama.cpp to `f05a6d71a0f3dbf0730b56a1abbad41c0f42e63d` by @localai-bot in https://github.com/mudler/LocalAI/pull/5340
* chore(deps): bump whisper.cpp by @mudler in https://github.com/mudler/LocalAI/pull/5338
* feat: Add sycl support for whisper.cpp by @mudler in https://github.com/mudler/LocalAI/pull/5341
* chore: :arrow_up: Update ggml-org/llama.cpp to `33eff4024084d1f0c8441b79f7208a52fad79858` by @localai-bot in https://github.com/mudler/LocalAI/pull/5343
* chore: :arrow_up: Update ggml-org/llama.cpp to `15e6125a397f6086c1dfdf7584acdb7c730313dc` by @localai-bot in https://github.com/mudler/LocalAI/pull/5345
* chore: :arrow_up: Update ggml-org/whisper.cpp to `2e310b841e0b4e7cf00890b53411dd9f8578f243` by @localai-bot in https://github.com/mudler/LocalAI/pull/4785
* chore: :arrow_up: Update ggml-org/llama.cpp to `9a390c4829cd3058d26a2e2c09d16e3fd12bf1b1` by @localai-bot in https://github.com/mudler/LocalAI/pull/5351
* chore(deps): bump dependabot/fetch-metadata from 2.3.0 to 2.4.0 by @dependabot in https://github.com/mudler/LocalAI/pull/5355
* chore(deps): bump securego/gosec from 2.22.3 to 2.22.4 by @dependabot in https://github.com/mudler/LocalAI/pull/5356
### Other Changes
* docs: :arrow_up: update docs version mudler/LocalAI by @localai-bot in https://github.com/mudler/LocalAI/pull/5191
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/5217
* fix(ci): add clang by @mudler in https://github.com/mudler/LocalAI/pull/5242
* chore(deps): bump grpcio to 1.72.0 by @mudler in https://github.com/mudler/LocalAI/pull/5244
* feat(swagger): update swagger by @localai-bot in https://github.com/mudler/LocalAI/pull/5253

&lt;/details&gt;

&lt;h2&gt;New Contributors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@baflo made their first contribution in https://github.com/mudler/LocalAI/pull/5200&lt;/li&gt;
&lt;li&gt;@Bloodis94 made their first contribution in https://github.com/mudler/LocalAI/pull/5239&lt;/li&gt;
&lt;li&gt;@sredman made their first contribution in https://github.com/mudler/LocalAI/pull/5255&lt;/li&gt;
&lt;li&gt;@Mohit-Gaur made their first contribution in https://github.com/mudler/LocalAI/pull/5256&lt;/li&gt;
&lt;li&gt;@wyattearp made their first contribution in https://github.com/mudler/LocalAI/pull/5279&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Full Changelog&lt;/strong&gt;: https://github.com/mudler/LocalAI/compare/v2.28.0...v2.29.0&lt;/p&gt;</content>
    <link href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0" rel="alternate"/>
  </entry>
</feed>
